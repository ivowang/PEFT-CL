2025-11-23 14:48:02,003 [trainer.py] => config: exps/sdlora.json
2025-11-23 14:48:02,004 [trainer.py] => prefix: reproduce
2025-11-23 14:48:02,005 [trainer.py] => dataset: cifar224
2025-11-23 14:48:02,005 [trainer.py] => memory_size: 0
2025-11-23 14:48:02,005 [trainer.py] => memory_per_class: 0
2025-11-23 14:48:02,005 [trainer.py] => fixed_memory: False
2025-11-23 14:48:02,005 [trainer.py] => shuffle: True
2025-11-23 14:48:02,005 [trainer.py] => init_cls: 10
2025-11-23 14:48:02,005 [trainer.py] => increment: 10
2025-11-23 14:48:02,005 [trainer.py] => model_name: sdlora
2025-11-23 14:48:02,005 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-23 14:48:02,006 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-23 14:48:02,006 [trainer.py] => seed: 1993
2025-11-23 14:48:02,006 [trainer.py] => scheduler: cosine
2025-11-23 14:48:02,006 [trainer.py] => min_lr: 0.005
2025-11-23 14:48:02,006 [trainer.py] => tuned_epoch: 20
2025-11-23 14:48:02,006 [trainer.py] => filepath: ./checkpoints/sdlora/cifar100/
2025-11-23 14:48:02,006 [trainer.py] => lora_rank: 10
2025-11-23 14:48:02,007 [trainer.py] => init_epoch: 20
2025-11-23 14:48:02,007 [trainer.py] => init_lr: 0.008
2025-11-23 14:48:02,007 [trainer.py] => init_milestones: [60, 120, 170]
2025-11-23 14:48:02,007 [trainer.py] => init_lr_decay: 0.1
2025-11-23 14:48:02,007 [trainer.py] => init_weight_decay: 0.0005
2025-11-23 14:48:02,007 [trainer.py] => epochs: 20
2025-11-23 14:48:02,007 [trainer.py] => lrate: 0.008
2025-11-23 14:48:02,007 [trainer.py] => milestones: [40, 70]
2025-11-23 14:48:02,007 [trainer.py] => lrate_decay: 0.0
2025-11-23 14:48:02,007 [trainer.py] => batch_size: 128
2025-11-23 14:48:02,007 [trainer.py] => weight_decay: 0.0002
2025-11-23 14:48:05,262 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-23 14:48:08,069 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-23 14:48:08,627 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-23 14:48:10,144 [trainer.py] => All params: 171965973
2025-11-23 14:48:10,146 [trainer.py] => Trainable params: 368661
2025-11-23 14:48:10,147 [sdlora.py] => Learning on 0-10
2025-11-23 14:58:49,320 [sdlora.py] => Task 0, Epoch 20/20 => Loss 0.182, Train_accy 94.24
2025-11-23 14:58:53,137 [trainer.py] => No NME accuracy.
2025-11-23 14:58:53,138 [trainer.py] => CNN: {'total': np.float64(98.9), '00-09': np.float64(98.9), 'old': 0, 'new': np.float64(98.9)}
2025-11-23 14:58:53,138 [trainer.py] => CNN top1 curve: [np.float64(98.9)]
2025-11-23 14:58:53,138 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-23 14:58:53,138 [trainer.py] => Average Accuracy (CNN): 98.9 

2025-11-23 14:58:53,142 [trainer.py] => All params: 171973663
2025-11-23 14:58:53,145 [trainer.py] => Trainable params: 376351
2025-11-23 14:58:53,147 [sdlora.py] => Learning on 10-20
2025-11-23 14:58:55,189 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-23 14:58:56,564 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
