2025-11-23 14:48:02,003 [trainer.py] => config: exps/sdlora.json
2025-11-23 14:48:02,004 [trainer.py] => prefix: reproduce
2025-11-23 14:48:02,005 [trainer.py] => dataset: cifar224
2025-11-23 14:48:02,005 [trainer.py] => memory_size: 0
2025-11-23 14:48:02,005 [trainer.py] => memory_per_class: 0
2025-11-23 14:48:02,005 [trainer.py] => fixed_memory: False
2025-11-23 14:48:02,005 [trainer.py] => shuffle: True
2025-11-23 14:48:02,005 [trainer.py] => init_cls: 10
2025-11-23 14:48:02,005 [trainer.py] => increment: 10
2025-11-23 14:48:02,005 [trainer.py] => model_name: sdlora
2025-11-23 14:48:02,005 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-23 14:48:02,006 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-23 14:48:02,006 [trainer.py] => seed: 1993
2025-11-23 14:48:02,006 [trainer.py] => scheduler: cosine
2025-11-23 14:48:02,006 [trainer.py] => min_lr: 0.005
2025-11-23 14:48:02,006 [trainer.py] => tuned_epoch: 20
2025-11-23 14:48:02,006 [trainer.py] => filepath: ./checkpoints/sdlora/cifar100/
2025-11-23 14:48:02,006 [trainer.py] => lora_rank: 10
2025-11-23 14:48:02,007 [trainer.py] => init_epoch: 20
2025-11-23 14:48:02,007 [trainer.py] => init_lr: 0.008
2025-11-23 14:48:02,007 [trainer.py] => init_milestones: [60, 120, 170]
2025-11-23 14:48:02,007 [trainer.py] => init_lr_decay: 0.1
2025-11-23 14:48:02,007 [trainer.py] => init_weight_decay: 0.0005
2025-11-23 14:48:02,007 [trainer.py] => epochs: 20
2025-11-23 14:48:02,007 [trainer.py] => lrate: 0.008
2025-11-23 14:48:02,007 [trainer.py] => milestones: [40, 70]
2025-11-23 14:48:02,007 [trainer.py] => lrate_decay: 0.0
2025-11-23 14:48:02,007 [trainer.py] => batch_size: 128
2025-11-23 14:48:02,007 [trainer.py] => weight_decay: 0.0002
2025-11-23 14:48:05,262 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-23 14:48:08,069 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-23 14:48:08,627 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-23 14:48:10,144 [trainer.py] => All params: 171965973
2025-11-23 14:48:10,146 [trainer.py] => Trainable params: 368661
2025-11-23 14:48:10,147 [sdlora.py] => Learning on 0-10
2025-11-23 14:58:49,320 [sdlora.py] => Task 0, Epoch 20/20 => Loss 0.182, Train_accy 94.24
2025-11-23 14:58:53,137 [trainer.py] => No NME accuracy.
2025-11-23 14:58:53,138 [trainer.py] => CNN: {'total': np.float64(98.9), '00-09': np.float64(98.9), 'old': 0, 'new': np.float64(98.9)}
2025-11-23 14:58:53,138 [trainer.py] => CNN top1 curve: [np.float64(98.9)]
2025-11-23 14:58:53,138 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-23 14:58:53,138 [trainer.py] => Average Accuracy (CNN): 98.9 

2025-11-23 14:58:53,142 [trainer.py] => All params: 171973663
2025-11-23 14:58:53,145 [trainer.py] => Trainable params: 376351
2025-11-23 14:58:53,147 [sdlora.py] => Learning on 10-20
2025-11-23 14:58:55,189 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-23 14:58:56,564 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 06:58:35,988 [trainer.py] => config: exps/sdlora.json
2025-11-27 06:58:35,989 [trainer.py] => prefix: reproduce
2025-11-27 06:58:35,989 [trainer.py] => dataset: cifar224
2025-11-27 06:58:35,989 [trainer.py] => memory_size: 0
2025-11-27 06:58:35,989 [trainer.py] => memory_per_class: 0
2025-11-27 06:58:35,989 [trainer.py] => fixed_memory: False
2025-11-27 06:58:35,989 [trainer.py] => shuffle: True
2025-11-27 06:58:35,989 [trainer.py] => init_cls: 10
2025-11-27 06:58:35,989 [trainer.py] => increment: 10
2025-11-27 06:58:35,989 [trainer.py] => model_name: sdlora
2025-11-27 06:58:35,989 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 06:58:35,989 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 06:58:35,989 [trainer.py] => seed: 1993
2025-11-27 06:58:35,989 [trainer.py] => scheduler: cosine
2025-11-27 06:58:35,989 [trainer.py] => min_lr: 0.005
2025-11-27 06:58:35,989 [trainer.py] => tuned_epoch: 20
2025-11-27 06:58:35,989 [trainer.py] => filepath: ./checkpoints/sdlora/cifar100/
2025-11-27 06:58:35,989 [trainer.py] => lora_rank: 10
2025-11-27 06:58:35,989 [trainer.py] => init_epoch: 20
2025-11-27 06:58:35,989 [trainer.py] => init_lr: 0.008
2025-11-27 06:58:35,989 [trainer.py] => init_milestones: [60, 120, 170]
2025-11-27 06:58:35,990 [trainer.py] => init_lr_decay: 0.1
2025-11-27 06:58:35,990 [trainer.py] => init_weight_decay: 0.0005
2025-11-27 06:58:35,990 [trainer.py] => epochs: 20
2025-11-27 06:58:35,990 [trainer.py] => lrate: 0.008
2025-11-27 06:58:35,990 [trainer.py] => milestones: [40, 70]
2025-11-27 06:58:35,990 [trainer.py] => lrate_decay: 0.0
2025-11-27 06:58:35,990 [trainer.py] => batch_size: 128
2025-11-27 06:58:35,990 [trainer.py] => weight_decay: 0.0002
2025-11-27 06:58:37,975 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-27 06:58:40,173 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 06:58:40,495 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 06:58:41,824 [trainer.py] => All params: 171965973
2025-11-27 06:58:41,825 [trainer.py] => Trainable params: 368661
2025-11-27 06:58:41,825 [sdlora.py] => Learning on 0-10
2025-11-27 07:08:35,816 [sdlora.py] => Task 0, Epoch 20/20 => Loss 0.181, Train_accy 94.16
2025-11-27 07:08:39,129 [trainer.py] => No NME accuracy.
2025-11-27 07:08:39,129 [trainer.py] => CNN: {'total': np.float64(99.0), '00-09': np.float64(99.0), 'old': 0, 'new': np.float64(99.0)}
2025-11-27 07:08:39,129 [trainer.py] => CNN top1 curve: [np.float64(99.0)]
2025-11-27 07:08:39,129 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-27 07:08:39,129 [trainer.py] => Average Accuracy (CNN): 99.0 

2025-11-27 07:08:39,131 [trainer.py] => All params: 171973663
2025-11-27 07:08:39,133 [trainer.py] => Trainable params: 376351
2025-11-27 07:08:39,136 [sdlora.py] => Learning on 10-20
2025-11-27 07:08:40,346 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 07:08:40,940 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 07:15:52,230 [trainer.py] => config: exps/sdlora.json
2025-11-27 07:15:52,232 [trainer.py] => prefix: reproduce
2025-11-27 07:15:52,232 [trainer.py] => dataset: cifar224
2025-11-27 07:15:52,232 [trainer.py] => memory_size: 0
2025-11-27 07:15:52,232 [trainer.py] => memory_per_class: 0
2025-11-27 07:15:52,232 [trainer.py] => fixed_memory: False
2025-11-27 07:15:52,232 [trainer.py] => shuffle: True
2025-11-27 07:15:52,232 [trainer.py] => init_cls: 10
2025-11-27 07:15:52,232 [trainer.py] => increment: 10
2025-11-27 07:15:52,232 [trainer.py] => model_name: sdlora
2025-11-27 07:15:52,232 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 07:15:52,232 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 07:15:52,232 [trainer.py] => seed: 1993
2025-11-27 07:15:52,232 [trainer.py] => scheduler: cosine
2025-11-27 07:15:52,232 [trainer.py] => min_lr: 0.005
2025-11-27 07:15:52,232 [trainer.py] => tuned_epoch: 20
2025-11-27 07:15:52,233 [trainer.py] => filepath: ./checkpoints/sdlora/cifar100/
2025-11-27 07:15:52,233 [trainer.py] => lora_rank: 10
2025-11-27 07:15:52,233 [trainer.py] => init_epoch: 20
2025-11-27 07:15:52,233 [trainer.py] => init_lr: 0.008
2025-11-27 07:15:52,233 [trainer.py] => init_milestones: [60, 120, 170]
2025-11-27 07:15:52,233 [trainer.py] => init_lr_decay: 0.1
2025-11-27 07:15:52,233 [trainer.py] => init_weight_decay: 0.0005
2025-11-27 07:15:52,233 [trainer.py] => epochs: 20
2025-11-27 07:15:52,233 [trainer.py] => lrate: 0.008
2025-11-27 07:15:52,233 [trainer.py] => milestones: [40, 70]
2025-11-27 07:15:52,233 [trainer.py] => lrate_decay: 0.0
2025-11-27 07:15:52,233 [trainer.py] => batch_size: 128
2025-11-27 07:15:52,233 [trainer.py] => weight_decay: 0.0002
2025-11-27 07:15:54,768 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-27 07:15:56,965 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 07:15:57,485 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 07:15:58,768 [trainer.py] => All params: 171965973
2025-11-27 07:15:58,769 [trainer.py] => Trainable params: 368661
2025-11-27 07:15:58,770 [sdlora.py] => Learning on 0-10
2025-11-27 07:25:56,249 [sdlora.py] => Task 0, Epoch 20/20 => Loss 0.182, Train_accy 94.18
2025-11-27 07:25:59,715 [trainer.py] => No NME accuracy.
2025-11-27 07:25:59,716 [trainer.py] => CNN: {'total': np.float64(99.0), '00-09': np.float64(99.0), 'old': 0, 'new': np.float64(99.0)}
2025-11-27 07:25:59,716 [trainer.py] => CNN top1 curve: [np.float64(99.0)]
2025-11-27 07:25:59,716 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-27 07:25:59,717 [trainer.py] => Average Accuracy (CNN): 99.0 

2025-11-27 07:25:59,719 [trainer.py] => All params: 171973663
2025-11-27 07:25:59,720 [trainer.py] => Trainable params: 376351
2025-11-27 07:25:59,721 [sdlora.py] => Learning on 10-20
2025-11-27 07:26:00,916 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 07:26:01,280 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 07:36:55,399 [sdlora.py] => Task 1, Epoch 20/20 => Loss 0.225, Train_accy 85.50
2025-11-27 07:37:01,981 [trainer.py] => No NME accuracy.
2025-11-27 07:37:01,982 [trainer.py] => CNN: {'total': np.float64(96.25), '00-09': np.float64(96.9), '10-19': np.float64(95.6), 'old': np.float64(96.9), 'new': np.float64(95.6)}
2025-11-27 07:37:01,982 [trainer.py] => CNN top1 curve: [np.float64(99.0), np.float64(96.25)]
2025-11-27 07:37:01,983 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.8)]

2025-11-27 07:37:01,983 [trainer.py] => Average Accuracy (CNN): 97.625 

2025-11-27 07:37:01,985 [trainer.py] => All params: 171981353
2025-11-27 07:37:01,986 [trainer.py] => Trainable params: 384041
2025-11-27 07:37:01,990 [sdlora.py] => Learning on 20-30
2025-11-27 07:37:03,752 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 07:37:04,273 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
