2025-11-24 07:12:12,487 [trainer.py] => config: exps/coscl_c100.json
2025-11-24 07:12:12,488 [trainer.py] => prefix: reproduce
2025-11-24 07:12:12,488 [trainer.py] => dataset: cifar100
2025-11-24 07:12:12,488 [trainer.py] => memory_size: 0
2025-11-24 07:12:12,488 [trainer.py] => memory_per_class: 0
2025-11-24 07:12:12,488 [trainer.py] => fixed_memory: False
2025-11-24 07:12:12,488 [trainer.py] => shuffle: True
2025-11-24 07:12:12,488 [trainer.py] => init_cls: 10
2025-11-24 07:12:12,488 [trainer.py] => increment: 10
2025-11-24 07:12:12,488 [trainer.py] => model_name: coscl
2025-11-24 07:12:12,488 [trainer.py] => backbone_type: coscl_net
2025-11-24 07:12:12,488 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-24 07:12:12,488 [trainer.py] => seed: 0
2025-11-24 07:12:12,488 [trainer.py] => batch_size: 256
2025-11-24 07:12:12,488 [trainer.py] => num_workers: 4
2025-11-24 07:12:12,488 [trainer.py] => coscl_lamb: 10000.0
2025-11-24 07:12:12,488 [trainer.py] => coscl_lamb1: 0.02
2025-11-24 07:12:12,488 [trainer.py] => coscl_s_gate: 100.0
2025-11-24 07:12:12,488 [trainer.py] => coscl_use_TG: False
2025-11-24 07:12:12,488 [trainer.py] => coscl_nepochs: 100
2025-11-24 07:12:12,488 [trainer.py] => coscl_lr: 0.001
2025-11-24 07:12:12,489 [trainer.py] => coscl_lr_min: 1e-06
2025-11-24 07:12:12,489 [trainer.py] => coscl_lr_factor: 3
2025-11-24 07:12:12,489 [trainer.py] => coscl_lr_patience: 5
2025-11-24 07:12:14,500 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-24 07:12:15,148 [trainer.py] => All params: 0
2025-11-24 07:12:15,148 [trainer.py] => Trainable params: 0
2025-11-24 07:12:16,180 [coscl.py] => Initialized CoSCL model with 10 tasks
2025-11-24 07:12:19,875 [coscl.py] => Epoch 1/100 | Train: loss=2.280, acc=13.3% | Val: loss=2.066, acc=28.8% | lr=0.001000
2025-11-24 07:12:21,395 [coscl.py] => Epoch 2/100 | Train: loss=2.055, acc=26.8% | Val: loss=1.813, acc=37.2% | lr=0.001000
2025-11-24 07:12:23,287 [coscl.py] => Epoch 3/100 | Train: loss=1.911, acc=33.2% | Val: loss=1.681, acc=44.7% | lr=0.001000
2025-11-24 07:12:25,066 [coscl.py] => Epoch 4/100 | Train: loss=1.780, acc=39.1% | Val: loss=1.533, acc=47.1% | lr=0.001000
2025-11-24 07:12:26,601 [coscl.py] => Epoch 5/100 | Train: loss=1.685, acc=42.9% | Val: loss=1.453, acc=49.8% | lr=0.001000
2025-11-24 07:12:28,193 [coscl.py] => Epoch 6/100 | Train: loss=1.646, acc=44.2% | Val: loss=1.372, acc=52.0% | lr=0.001000
2025-11-24 07:12:29,832 [coscl.py] => Epoch 7/100 | Train: loss=1.599, acc=46.8% | Val: loss=1.376, acc=53.3% | lr=0.001000
2025-11-24 07:12:31,385 [coscl.py] => Epoch 8/100 | Train: loss=1.552, acc=49.1% | Val: loss=1.331, acc=53.8% | lr=0.001000
2025-11-24 07:12:32,909 [coscl.py] => Epoch 9/100 | Train: loss=1.519, acc=49.8% | Val: loss=1.277, acc=55.6% | lr=0.001000
2025-11-24 07:12:34,507 [coscl.py] => Epoch 10/100 | Train: loss=1.501, acc=50.5% | Val: loss=1.246, acc=56.6% | lr=0.001000
2025-11-24 07:12:36,155 [coscl.py] => Epoch 11/100 | Train: loss=1.474, acc=51.9% | Val: loss=1.235, acc=56.2% | lr=0.001000
2025-11-24 07:12:37,738 [coscl.py] => Epoch 12/100 | Train: loss=1.432, acc=53.6% | Val: loss=1.207, acc=57.6% | lr=0.001000
2025-11-24 07:12:39,375 [coscl.py] => Epoch 13/100 | Train: loss=1.433, acc=53.0% | Val: loss=1.195, acc=58.6% | lr=0.001000
2025-11-24 07:12:40,926 [coscl.py] => Epoch 14/100 | Train: loss=1.424, acc=53.5% | Val: loss=1.221, acc=57.3% | lr=0.001000
2025-11-24 07:12:42,447 [coscl.py] => Epoch 15/100 | Train: loss=1.406, acc=54.5% | Val: loss=1.125, acc=61.6% | lr=0.001000
2025-11-24 07:12:44,165 [coscl.py] => Epoch 16/100 | Train: loss=1.379, acc=55.6% | Val: loss=1.142, acc=60.7% | lr=0.001000
2025-11-24 07:12:45,691 [coscl.py] => Epoch 17/100 | Train: loss=1.365, acc=55.8% | Val: loss=1.102, acc=62.3% | lr=0.001000
2025-11-24 07:12:47,232 [coscl.py] => Epoch 18/100 | Train: loss=1.345, acc=55.6% | Val: loss=1.104, acc=62.1% | lr=0.001000
2025-11-24 07:12:48,781 [coscl.py] => Epoch 19/100 | Train: loss=1.334, acc=57.0% | Val: loss=1.045, acc=63.7% | lr=0.001000
2025-11-24 07:12:50,425 [coscl.py] => Epoch 20/100 | Train: loss=1.328, acc=57.2% | Val: loss=1.061, acc=63.1% | lr=0.001000
2025-11-24 07:12:51,947 [coscl.py] => Epoch 21/100 | Train: loss=1.311, acc=58.0% | Val: loss=1.036, acc=64.8% | lr=0.001000
2025-11-24 07:12:53,598 [coscl.py] => Epoch 22/100 | Train: loss=1.302, acc=58.6% | Val: loss=1.011, acc=65.2% | lr=0.001000
2025-11-24 07:12:55,285 [coscl.py] => Epoch 23/100 | Train: loss=1.299, acc=59.2% | Val: loss=1.026, acc=64.3% | lr=0.001000
2025-11-24 07:12:56,897 [coscl.py] => Epoch 24/100 | Train: loss=1.278, acc=59.1% | Val: loss=0.989, acc=65.7% | lr=0.001000
2025-11-24 07:12:58,460 [coscl.py] => Epoch 25/100 | Train: loss=1.262, acc=60.2% | Val: loss=0.977, acc=66.8% | lr=0.001000
2025-11-24 07:13:00,015 [coscl.py] => Epoch 26/100 | Train: loss=1.260, acc=60.4% | Val: loss=0.959, acc=67.0% | lr=0.001000
2025-11-24 07:13:01,605 [coscl.py] => Epoch 27/100 | Train: loss=1.258, acc=60.2% | Val: loss=0.961, acc=66.9% | lr=0.001000
2025-11-24 07:13:03,192 [coscl.py] => Epoch 28/100 | Train: loss=1.239, acc=60.9% | Val: loss=0.931, acc=68.2% | lr=0.001000
2025-11-24 07:13:04,743 [coscl.py] => Epoch 29/100 | Train: loss=1.226, acc=61.8% | Val: loss=0.935, acc=68.5% | lr=0.001000
2025-11-24 07:13:06,283 [coscl.py] => Epoch 30/100 | Train: loss=1.211, acc=62.2% | Val: loss=0.917, acc=68.7% | lr=0.001000
2025-11-24 07:13:07,947 [coscl.py] => Epoch 31/100 | Train: loss=1.200, acc=62.7% | Val: loss=0.915, acc=68.9% | lr=0.001000
2025-11-24 07:13:09,496 [coscl.py] => Epoch 32/100 | Train: loss=1.184, acc=63.2% | Val: loss=0.963, acc=67.0% | lr=0.001000
2025-11-24 07:13:12,456 [coscl.py] => Epoch 33/100 | Train: loss=1.193, acc=63.1% | Val: loss=0.876, acc=70.4% | lr=0.001000
2025-11-24 07:13:14,162 [coscl.py] => Epoch 34/100 | Train: loss=1.189, acc=62.9% | Val: loss=0.895, acc=68.7% | lr=0.001000
2025-11-24 07:13:15,810 [coscl.py] => Epoch 35/100 | Train: loss=1.176, acc=63.3% | Val: loss=0.892, acc=69.1% | lr=0.001000
2025-11-24 07:13:17,335 [coscl.py] => Epoch 36/100 | Train: loss=1.167, acc=63.8% | Val: loss=0.857, acc=70.6% | lr=0.001000
2025-11-24 07:13:18,957 [coscl.py] => Epoch 37/100 | Train: loss=1.168, acc=63.8% | Val: loss=0.851, acc=70.7% | lr=0.001000
2025-11-24 07:13:20,835 [coscl.py] => Epoch 38/100 | Train: loss=1.165, acc=64.5% | Val: loss=0.839, acc=71.5% | lr=0.001000
2025-11-24 07:13:22,400 [coscl.py] => Epoch 39/100 | Train: loss=1.151, acc=64.5% | Val: loss=0.848, acc=70.7% | lr=0.001000
2025-11-24 07:13:23,933 [coscl.py] => Epoch 40/100 | Train: loss=1.152, acc=64.1% | Val: loss=0.892, acc=68.8% | lr=0.001000
2025-11-24 07:13:25,559 [coscl.py] => Epoch 41/100 | Train: loss=1.146, acc=64.4% | Val: loss=0.806, acc=72.6% | lr=0.001000
2025-11-24 07:13:27,188 [coscl.py] => Epoch 42/100 | Train: loss=1.135, acc=64.5% | Val: loss=0.782, acc=73.3% | lr=0.001000
2025-11-24 07:13:28,839 [coscl.py] => Epoch 43/100 | Train: loss=1.112, acc=65.7% | Val: loss=0.805, acc=72.8% | lr=0.001000
2025-11-24 07:13:30,535 [coscl.py] => Epoch 44/100 | Train: loss=1.108, acc=66.2% | Val: loss=0.782, acc=74.2% | lr=0.001000
2025-11-24 07:13:32,143 [coscl.py] => Epoch 45/100 | Train: loss=1.102, acc=66.6% | Val: loss=0.779, acc=74.0% | lr=0.001000
2025-11-24 07:13:33,723 [coscl.py] => Epoch 46/100 | Train: loss=1.097, acc=66.3% | Val: loss=0.778, acc=73.5% | lr=0.001000
2025-11-24 07:13:35,317 [coscl.py] => Epoch 47/100 | Train: loss=1.105, acc=66.5% | Val: loss=0.799, acc=72.3% | lr=0.001000
2025-11-24 07:13:36,859 [coscl.py] => Epoch 48/100 | Train: loss=1.110, acc=66.1% | Val: loss=0.754, acc=74.6% | lr=0.001000
2025-11-24 07:13:38,526 [coscl.py] => Epoch 49/100 | Train: loss=1.086, acc=67.2% | Val: loss=0.759, acc=74.1% | lr=0.001000
2025-11-24 07:13:40,149 [coscl.py] => Epoch 50/100 | Train: loss=1.083, acc=66.8% | Val: loss=0.751, acc=75.0% | lr=0.001000
2025-11-24 07:13:41,677 [coscl.py] => Epoch 51/100 | Train: loss=1.089, acc=66.3% | Val: loss=0.809, acc=72.2% | lr=0.001000
2025-11-24 07:13:43,334 [coscl.py] => Epoch 52/100 | Train: loss=1.078, acc=66.8% | Val: loss=0.732, acc=75.1% | lr=0.001000
2025-11-24 07:13:44,883 [coscl.py] => Epoch 53/100 | Train: loss=1.066, acc=67.6% | Val: loss=0.716, acc=76.2% | lr=0.001000
2025-11-24 07:13:46,511 [coscl.py] => Epoch 54/100 | Train: loss=1.054, acc=68.1% | Val: loss=0.722, acc=75.5% | lr=0.001000
2025-11-24 07:13:48,112 [coscl.py] => Epoch 55/100 | Train: loss=1.057, acc=68.2% | Val: loss=0.705, acc=76.1% | lr=0.001000
2025-11-24 07:13:49,648 [coscl.py] => Epoch 56/100 | Train: loss=1.062, acc=68.0% | Val: loss=0.753, acc=74.5% | lr=0.001000
2025-11-24 07:13:51,246 [coscl.py] => Epoch 57/100 | Train: loss=1.054, acc=68.2% | Val: loss=0.708, acc=76.2% | lr=0.001000
2025-11-24 07:13:52,832 [coscl.py] => Epoch 58/100 | Train: loss=1.050, acc=68.8% | Val: loss=0.702, acc=76.6% | lr=0.001000
2025-11-24 07:13:54,344 [coscl.py] => Epoch 59/100 | Train: loss=1.031, acc=68.8% | Val: loss=0.679, acc=76.9% | lr=0.001000
2025-11-24 07:13:55,985 [coscl.py] => Epoch 60/100 | Train: loss=1.026, acc=69.1% | Val: loss=0.689, acc=77.5% | lr=0.001000
2025-11-24 07:13:57,539 [coscl.py] => Epoch 61/100 | Train: loss=1.029, acc=69.5% | Val: loss=0.669, acc=77.7% | lr=0.001000
2025-11-24 07:13:59,060 [coscl.py] => Epoch 62/100 | Train: loss=1.020, acc=69.1% | Val: loss=0.663, acc=77.5% | lr=0.001000
2025-11-24 07:14:00,647 [coscl.py] => Epoch 63/100 | Train: loss=1.020, acc=69.1% | Val: loss=0.652, acc=77.4% | lr=0.001000
2025-11-24 07:14:02,313 [coscl.py] => Epoch 64/100 | Train: loss=1.009, acc=69.6% | Val: loss=0.642, acc=77.6% | lr=0.001000
2025-11-24 07:14:03,856 [coscl.py] => Epoch 65/100 | Train: loss=1.015, acc=70.2% | Val: loss=0.644, acc=78.8% | lr=0.001000
2025-11-24 07:14:05,414 [coscl.py] => Epoch 66/100 | Train: loss=1.001, acc=69.8% | Val: loss=0.656, acc=78.1% | lr=0.001000
2025-11-24 07:14:07,064 [coscl.py] => Epoch 67/100 | Train: loss=1.024, acc=68.3% | Val: loss=0.647, acc=78.5% | lr=0.001000
2025-11-24 07:14:08,596 [coscl.py] => Epoch 68/100 | Train: loss=0.977, acc=71.6% | Val: loss=0.633, acc=78.7% | lr=0.001000
2025-11-24 07:14:12,646 [coscl.py] => Epoch 69/100 | Train: loss=1.006, acc=70.4% | Val: loss=0.639, acc=78.7% | lr=0.001000
2025-11-24 07:14:14,637 [coscl.py] => Epoch 70/100 | Train: loss=0.994, acc=70.4% | Val: loss=0.644, acc=78.9% | lr=0.001000
2025-11-24 07:14:16,231 [coscl.py] => Epoch 71/100 | Train: loss=0.996, acc=70.1% | Val: loss=0.642, acc=78.1% | lr=0.001000
2025-11-24 07:14:17,733 [coscl.py] => Epoch 72/100 | Train: loss=0.971, acc=71.4% | Val: loss=0.604, acc=80.5% | lr=0.001000
2025-11-24 07:14:19,553 [coscl.py] => Epoch 73/100 | Train: loss=0.972, acc=71.4% | Val: loss=0.599, acc=80.5% | lr=0.001000
2025-11-24 07:14:21,451 [coscl.py] => Epoch 74/100 | Train: loss=0.975, acc=71.6% | Val: loss=0.604, acc=80.5% | lr=0.001000
2025-11-24 07:14:23,027 [coscl.py] => Epoch 75/100 | Train: loss=0.971, acc=71.5% | Val: loss=0.592, acc=81.1% | lr=0.001000
2025-11-24 07:14:24,552 [coscl.py] => Epoch 76/100 | Train: loss=0.971, acc=71.1% | Val: loss=0.608, acc=79.6% | lr=0.001000
2025-11-24 07:14:26,187 [coscl.py] => Epoch 77/100 | Train: loss=0.960, acc=71.2% | Val: loss=0.587, acc=80.7% | lr=0.001000
2025-11-24 07:14:27,771 [coscl.py] => Epoch 78/100 | Train: loss=0.952, acc=72.1% | Val: loss=0.589, acc=80.9% | lr=0.001000
2025-11-24 07:14:29,318 [coscl.py] => Epoch 79/100 | Train: loss=0.945, acc=72.2% | Val: loss=0.589, acc=80.6% | lr=0.001000
2025-11-24 07:14:30,946 [coscl.py] => Epoch 80/100 | Train: loss=0.956, acc=71.9% | Val: loss=0.599, acc=80.0% | lr=0.001000
2025-11-24 07:14:32,574 [coscl.py] => Epoch 81/100 | Train: loss=0.950, acc=72.3% | Val: loss=0.575, acc=81.1% | lr=0.001000
2025-11-24 07:14:34,108 [coscl.py] => Epoch 82/100 | Train: loss=0.935, acc=73.6% | Val: loss=0.560, acc=82.0% | lr=0.001000
2025-11-24 07:14:35,719 [coscl.py] => Epoch 83/100 | Train: loss=0.936, acc=72.9% | Val: loss=0.567, acc=81.7% | lr=0.001000
2025-11-24 07:14:37,334 [coscl.py] => Epoch 84/100 | Train: loss=0.931, acc=73.2% | Val: loss=0.563, acc=82.1% | lr=0.001000
2025-11-24 07:14:38,913 [coscl.py] => Epoch 85/100 | Train: loss=0.931, acc=72.7% | Val: loss=0.568, acc=80.6% | lr=0.001000
2025-11-24 07:14:40,669 [coscl.py] => Epoch 86/100 | Train: loss=0.936, acc=72.9% | Val: loss=0.552, acc=82.4% | lr=0.001000
2025-11-24 07:14:42,259 [coscl.py] => Epoch 87/100 | Train: loss=0.931, acc=73.5% | Val: loss=0.561, acc=81.6% | lr=0.001000
2025-11-24 07:14:43,844 [coscl.py] => Epoch 88/100 | Train: loss=0.928, acc=73.3% | Val: loss=0.568, acc=81.4% | lr=0.001000
2025-11-24 07:14:45,460 [coscl.py] => Epoch 89/100 | Train: loss=0.915, acc=73.3% | Val: loss=0.538, acc=82.6% | lr=0.001000
2025-11-24 07:14:47,073 [coscl.py] => Epoch 90/100 | Train: loss=0.914, acc=73.5% | Val: loss=0.536, acc=82.9% | lr=0.001000
2025-11-24 07:14:48,583 [coscl.py] => Epoch 91/100 | Train: loss=0.920, acc=73.4% | Val: loss=0.522, acc=83.3% | lr=0.001000
2025-11-24 07:14:50,100 [coscl.py] => Epoch 92/100 | Train: loss=0.899, acc=74.1% | Val: loss=0.521, acc=82.8% | lr=0.001000
2025-11-24 07:14:51,734 [coscl.py] => Epoch 93/100 | Train: loss=0.907, acc=74.2% | Val: loss=0.521, acc=82.8% | lr=0.001000
2025-11-24 07:14:53,412 [coscl.py] => Epoch 94/100 | Train: loss=0.916, acc=73.7% | Val: loss=0.525, acc=83.4% | lr=0.001000
2025-11-24 07:14:54,979 [coscl.py] => Epoch 95/100 | Train: loss=0.889, acc=74.9% | Val: loss=0.502, acc=83.8% | lr=0.001000
2025-11-24 07:14:56,499 [coscl.py] => Epoch 96/100 | Train: loss=0.897, acc=73.9% | Val: loss=0.511, acc=84.2% | lr=0.001000
2025-11-24 07:14:58,225 [coscl.py] => Epoch 97/100 | Train: loss=0.889, acc=74.6% | Val: loss=0.534, acc=82.3% | lr=0.001000
2025-11-24 07:14:59,823 [coscl.py] => Epoch 98/100 | Train: loss=0.896, acc=74.5% | Val: loss=0.508, acc=83.5% | lr=0.001000
2025-11-24 07:15:01,334 [coscl.py] => Epoch 99/100 | Train: loss=0.889, acc=75.0% | Val: loss=0.505, acc=84.1% | lr=0.001000
2025-11-24 07:15:02,957 [coscl.py] => Epoch 100/100 | Train: loss=0.894, acc=74.3% | Val: loss=0.487, acc=85.1% | lr=0.001000
2025-11-24 07:15:04,869 [trainer.py] => No NME accuracy.
2025-11-24 07:15:04,869 [trainer.py] => CNN: {'total': np.float64(72.7), '00-09': np.float64(72.7), 'old': 0, 'new': np.float64(72.7)}
2025-11-24 07:15:04,869 [trainer.py] => CNN top1 curve: [np.float64(72.7)]
2025-11-24 07:15:04,869 [trainer.py] => CNN top5 curve: [np.float64(98.0)]

2025-11-24 07:15:04,870 [trainer.py] => Average Accuracy (CNN): 72.7 

2025-11-24 07:15:04,871 [trainer.py] => All params: 773260
2025-11-24 07:15:04,871 [trainer.py] => Trainable params: 773260
2025-11-24 07:15:06,656 [coscl.py] => Epoch 1/100 | Train: loss=1.854, acc=40.0% | Val: loss=1.097, acc=64.0% | lr=0.001000
2025-11-24 07:15:08,740 [coscl.py] => Epoch 2/100 | Train: loss=1.416, acc=58.6% | Val: loss=0.959, acc=69.3% | lr=0.001000
2025-11-24 07:15:10,913 [coscl.py] => Epoch 3/100 | Train: loss=1.321, acc=62.7% | Val: loss=0.893, acc=70.8% | lr=0.001000
2025-11-24 07:15:12,753 [coscl.py] => Epoch 4/100 | Train: loss=1.248, acc=64.8% | Val: loss=0.808, acc=73.4% | lr=0.001000
2025-11-24 07:15:14,561 [coscl.py] => Epoch 5/100 | Train: loss=1.223, acc=66.3% | Val: loss=0.776, acc=74.6% | lr=0.001000
2025-11-24 07:15:16,555 [coscl.py] => Epoch 6/100 | Train: loss=1.199, acc=67.4% | Val: loss=0.759, acc=75.0% | lr=0.001000
2025-11-24 07:15:18,304 [coscl.py] => Epoch 7/100 | Train: loss=1.193, acc=67.7% | Val: loss=0.777, acc=74.5% | lr=0.001000
2025-11-24 07:15:20,079 [coscl.py] => Epoch 8/100 | Train: loss=1.185, acc=67.1% | Val: loss=0.727, acc=77.2% | lr=0.001000
2025-11-24 07:15:21,979 [coscl.py] => Epoch 9/100 | Train: loss=1.144, acc=69.9% | Val: loss=0.695, acc=77.9% | lr=0.001000
2025-11-24 07:15:23,671 [coscl.py] => Epoch 10/100 | Train: loss=1.145, acc=70.3% | Val: loss=0.674, acc=78.9% | lr=0.001000
2025-11-24 07:15:25,468 [coscl.py] => Epoch 11/100 | Train: loss=1.134, acc=70.2% | Val: loss=0.669, acc=78.2% | lr=0.001000
2025-11-24 07:15:27,170 [coscl.py] => Epoch 12/100 | Train: loss=1.137, acc=70.5% | Val: loss=0.682, acc=78.5% | lr=0.001000
2025-11-24 07:15:28,957 [coscl.py] => Epoch 13/100 | Train: loss=1.123, acc=71.5% | Val: loss=0.675, acc=78.5% | lr=0.001000
2025-11-24 07:15:30,761 [coscl.py] => Epoch 14/100 | Train: loss=1.110, acc=70.9% | Val: loss=0.642, acc=78.8% | lr=0.001000
2025-11-24 07:15:32,543 [coscl.py] => Epoch 15/100 | Train: loss=1.116, acc=71.0% | Val: loss=0.628, acc=80.2% | lr=0.001000
2025-11-24 07:15:34,332 [coscl.py] => Epoch 16/100 | Train: loss=1.117, acc=71.1% | Val: loss=0.618, acc=80.1% | lr=0.001000
2025-11-24 07:15:36,102 [coscl.py] => Epoch 17/100 | Train: loss=1.107, acc=72.1% | Val: loss=0.632, acc=79.2% | lr=0.001000
2025-11-24 07:15:38,376 [coscl.py] => Epoch 18/100 | Train: loss=1.106, acc=71.2% | Val: loss=0.671, acc=78.3% | lr=0.001000
2025-11-24 07:15:40,187 [coscl.py] => Epoch 19/100 | Train: loss=1.109, acc=71.9% | Val: loss=0.623, acc=80.0% | lr=0.001000
2025-11-24 07:15:41,861 [coscl.py] => Epoch 20/100 | Train: loss=1.106, acc=72.0% | Val: loss=0.616, acc=80.5% | lr=0.001000
2025-11-24 07:15:43,799 [coscl.py] => Epoch 21/100 | Train: loss=1.085, acc=72.6% | Val: loss=0.595, acc=80.9% | lr=0.001000
2025-11-24 07:15:45,469 [coscl.py] => Epoch 22/100 | Train: loss=1.073, acc=72.7% | Val: loss=0.595, acc=81.2% | lr=0.001000
2025-11-24 07:15:47,759 [coscl.py] => Epoch 23/100 | Train: loss=1.099, acc=72.1% | Val: loss=0.601, acc=80.7% | lr=0.001000
2025-11-24 07:15:50,070 [coscl.py] => Epoch 24/100 | Train: loss=1.096, acc=72.8% | Val: loss=0.597, acc=80.9% | lr=0.001000
2025-11-24 07:15:52,131 [coscl.py] => Epoch 25/100 | Train: loss=1.098, acc=72.0% | Val: loss=0.625, acc=79.9% | lr=0.001000
2025-11-24 07:15:54,223 [coscl.py] => Epoch 26/100 | Train: loss=1.095, acc=72.6% | Val: loss=0.590, acc=81.7% | lr=0.001000
2025-11-24 07:15:56,045 [coscl.py] => Epoch 27/100 | Train: loss=1.066, acc=74.0% | Val: loss=0.590, acc=81.2% | lr=0.001000
2025-11-24 07:15:57,814 [coscl.py] => Epoch 28/100 | Train: loss=1.086, acc=72.9% | Val: loss=0.587, acc=81.1% | lr=0.001000
2025-11-24 07:15:59,526 [coscl.py] => Epoch 29/100 | Train: loss=1.080, acc=72.8% | Val: loss=0.579, acc=81.6% | lr=0.001000
2025-11-24 07:16:01,413 [coscl.py] => Epoch 30/100 | Train: loss=1.069, acc=73.2% | Val: loss=0.570, acc=81.9% | lr=0.001000
2025-11-24 07:16:03,184 [coscl.py] => Epoch 31/100 | Train: loss=1.070, acc=73.4% | Val: loss=0.546, acc=83.3% | lr=0.001000
2025-11-24 07:16:04,922 [coscl.py] => Epoch 32/100 | Train: loss=1.076, acc=73.7% | Val: loss=0.553, acc=82.7% | lr=0.001000
2025-11-24 07:16:06,752 [coscl.py] => Epoch 33/100 | Train: loss=1.058, acc=73.7% | Val: loss=0.544, acc=83.0% | lr=0.001000
2025-11-24 07:16:08,473 [coscl.py] => Epoch 34/100 | Train: loss=1.059, acc=73.4% | Val: loss=0.565, acc=82.6% | lr=0.001000
2025-11-24 07:16:10,913 [coscl.py] => Epoch 35/100 | Train: loss=1.053, acc=74.1% | Val: loss=0.560, acc=82.2% | lr=0.001000
2025-11-24 07:16:12,740 [coscl.py] => Epoch 36/100 | Train: loss=1.059, acc=73.4% | Val: loss=0.566, acc=82.0% | lr=0.001000
2025-11-24 07:16:14,530 [coscl.py] => Epoch 37/100 | Train: loss=1.059, acc=73.6% | Val: loss=0.556, acc=82.8% | lr=0.001000
2025-11-24 07:16:16,322 [coscl.py] => Epoch 38/100 | Train: loss=1.049, acc=74.3% | Val: loss=0.517, acc=83.7% | lr=0.001000
2025-11-24 07:16:18,056 [coscl.py] => Epoch 39/100 | Train: loss=1.064, acc=73.0% | Val: loss=0.521, acc=83.6% | lr=0.001000
2025-11-24 07:16:19,889 [coscl.py] => Epoch 40/100 | Train: loss=1.053, acc=73.5% | Val: loss=0.544, acc=82.8% | lr=0.001000
2025-11-24 07:16:21,665 [coscl.py] => Epoch 41/100 | Train: loss=1.066, acc=73.6% | Val: loss=0.537, acc=83.4% | lr=0.001000
2025-11-24 07:16:23,346 [coscl.py] => Epoch 42/100 | Train: loss=1.039, acc=73.6% | Val: loss=0.504, acc=84.7% | lr=0.001000
2025-11-24 07:16:25,227 [coscl.py] => Epoch 43/100 | Train: loss=1.029, acc=75.6% | Val: loss=0.558, acc=82.1% | lr=0.001000
2025-11-24 07:16:26,929 [coscl.py] => Epoch 44/100 | Train: loss=1.046, acc=74.3% | Val: loss=0.532, acc=82.8% | lr=0.001000
2025-11-24 07:16:28,916 [coscl.py] => Epoch 45/100 | Train: loss=1.048, acc=74.4% | Val: loss=0.515, acc=84.1% | lr=0.001000
2025-11-24 07:16:30,734 [coscl.py] => Epoch 46/100 | Train: loss=1.039, acc=74.5% | Val: loss=0.526, acc=82.9% | lr=0.001000
2025-11-24 07:16:32,468 [coscl.py] => Epoch 47/100 | Train: loss=1.031, acc=75.2% | Val: loss=0.552, acc=82.5% | lr=0.001000
2025-11-24 07:16:34,303 [coscl.py] => Epoch 48/100 | Train: loss=1.026, acc=75.6% | Val: loss=0.499, acc=84.5% | lr=0.000333
2025-11-24 07:16:35,989 [coscl.py] => Epoch 49/100 | Train: loss=1.001, acc=75.7% | Val: loss=0.499, acc=84.7% | lr=0.000333
2025-11-24 07:16:38,200 [coscl.py] => Epoch 50/100 | Train: loss=0.993, acc=75.9% | Val: loss=0.496, acc=84.7% | lr=0.000333
2025-11-24 07:16:39,952 [coscl.py] => Epoch 51/100 | Train: loss=0.972, acc=76.4% | Val: loss=0.497, acc=84.5% | lr=0.000333
2025-11-24 07:16:41,691 [coscl.py] => Epoch 52/100 | Train: loss=0.983, acc=75.9% | Val: loss=0.491, acc=84.9% | lr=0.000333
2025-11-24 07:16:43,519 [coscl.py] => Epoch 53/100 | Train: loss=0.984, acc=75.7% | Val: loss=0.488, acc=85.3% | lr=0.000333
2025-11-24 07:16:45,266 [coscl.py] => Epoch 54/100 | Train: loss=0.966, acc=76.7% | Val: loss=0.480, acc=85.4% | lr=0.000333
2025-11-24 07:16:47,323 [coscl.py] => Epoch 55/100 | Train: loss=0.984, acc=75.6% | Val: loss=0.482, acc=85.3% | lr=0.000333
2025-11-24 07:16:49,092 [coscl.py] => Epoch 56/100 | Train: loss=0.973, acc=76.2% | Val: loss=0.502, acc=84.4% | lr=0.000333
2025-11-24 07:16:50,853 [coscl.py] => Epoch 57/100 | Train: loss=0.971, acc=76.4% | Val: loss=0.482, acc=85.4% | lr=0.000333
2025-11-24 07:16:52,698 [coscl.py] => Epoch 58/100 | Train: loss=0.967, acc=75.9% | Val: loss=0.470, acc=85.7% | lr=0.000333
2025-11-24 07:16:54,428 [coscl.py] => Epoch 59/100 | Train: loss=0.982, acc=75.6% | Val: loss=0.468, acc=85.6% | lr=0.000333
2025-11-24 07:16:56,424 [coscl.py] => Epoch 60/100 | Train: loss=0.977, acc=76.2% | Val: loss=0.474, acc=85.7% | lr=0.000333
2025-11-24 07:16:58,174 [coscl.py] => Epoch 61/100 | Train: loss=0.982, acc=75.9% | Val: loss=0.481, acc=85.5% | lr=0.000333
2025-11-24 07:16:59,970 [coscl.py] => Epoch 62/100 | Train: loss=0.960, acc=77.3% | Val: loss=0.476, acc=85.3% | lr=0.000333
2025-11-24 07:17:01,728 [coscl.py] => Epoch 63/100 | Train: loss=0.969, acc=75.9% | Val: loss=0.466, acc=85.7% | lr=0.000333
2025-11-24 07:17:03,833 [coscl.py] => Epoch 64/100 | Train: loss=0.969, acc=76.6% | Val: loss=0.480, acc=85.5% | lr=0.000333
2025-11-24 07:17:05,595 [coscl.py] => Epoch 65/100 | Train: loss=0.971, acc=76.2% | Val: loss=0.482, acc=85.3% | lr=0.000333
2025-11-24 07:17:07,286 [coscl.py] => Epoch 66/100 | Train: loss=0.960, acc=76.5% | Val: loss=0.478, acc=85.5% | lr=0.000333
2025-11-24 07:17:09,373 [coscl.py] => Epoch 67/100 | Train: loss=0.956, acc=77.2% | Val: loss=0.473, acc=85.8% | lr=0.000333
2025-11-24 07:17:11,131 [coscl.py] => Epoch 68/100 | Train: loss=0.979, acc=75.5% | Val: loss=0.468, acc=85.8% | lr=0.000333
2025-11-24 07:17:12,850 [coscl.py] => Epoch 69/100 | Train: loss=0.957, acc=76.7% | Val: loss=0.471, acc=85.9% | lr=0.000111
2025-11-24 07:17:14,771 [coscl.py] => Epoch 70/100 | Train: loss=0.948, acc=77.0% | Val: loss=0.465, acc=85.8% | lr=0.000111
2025-11-24 07:17:16,547 [coscl.py] => Epoch 71/100 | Train: loss=0.961, acc=75.7% | Val: loss=0.464, acc=85.8% | lr=0.000111
2025-11-24 07:17:18,210 [coscl.py] => Epoch 72/100 | Train: loss=0.944, acc=76.8% | Val: loss=0.465, acc=85.7% | lr=0.000111
2025-11-24 07:17:20,265 [coscl.py] => Epoch 73/100 | Train: loss=0.951, acc=75.9% | Val: loss=0.467, acc=85.8% | lr=0.000111
2025-11-24 07:17:21,949 [coscl.py] => Epoch 74/100 | Train: loss=0.935, acc=77.4% | Val: loss=0.470, acc=85.6% | lr=0.000111
2025-11-24 07:17:23,813 [coscl.py] => Epoch 75/100 | Train: loss=0.946, acc=76.7% | Val: loss=0.460, acc=86.0% | lr=0.000111
2025-11-24 07:17:25,549 [coscl.py] => Epoch 76/100 | Train: loss=0.951, acc=76.2% | Val: loss=0.461, acc=85.9% | lr=0.000111
2025-11-24 07:17:27,202 [coscl.py] => Epoch 77/100 | Train: loss=0.949, acc=76.5% | Val: loss=0.468, acc=85.7% | lr=0.000111
2025-11-24 07:17:29,331 [coscl.py] => Epoch 78/100 | Train: loss=0.948, acc=76.3% | Val: loss=0.459, acc=86.0% | lr=0.000111
2025-11-24 07:17:31,124 [coscl.py] => Epoch 79/100 | Train: loss=0.938, acc=77.4% | Val: loss=0.457, acc=86.2% | lr=0.000111
2025-11-24 07:17:32,851 [coscl.py] => Epoch 80/100 | Train: loss=0.948, acc=76.3% | Val: loss=0.461, acc=86.2% | lr=0.000111
2025-11-24 07:17:34,654 [coscl.py] => Epoch 81/100 | Train: loss=0.934, acc=76.9% | Val: loss=0.461, acc=86.0% | lr=0.000111
2025-11-24 07:17:36,689 [coscl.py] => Epoch 82/100 | Train: loss=0.939, acc=77.3% | Val: loss=0.458, acc=86.1% | lr=0.000111
2025-11-24 07:17:38,597 [coscl.py] => Epoch 83/100 | Train: loss=0.943, acc=76.4% | Val: loss=0.456, acc=86.1% | lr=0.000111
2025-11-24 07:17:40,420 [coscl.py] => Epoch 84/100 | Train: loss=0.961, acc=76.4% | Val: loss=0.464, acc=86.2% | lr=0.000111
2025-11-24 07:17:42,324 [coscl.py] => Epoch 85/100 | Train: loss=0.933, acc=77.4% | Val: loss=0.459, acc=86.0% | lr=0.000111
2025-11-24 07:17:44,131 [coscl.py] => Epoch 86/100 | Train: loss=0.941, acc=76.7% | Val: loss=0.452, acc=86.2% | lr=0.000111
2025-11-24 07:17:45,879 [coscl.py] => Epoch 87/100 | Train: loss=0.943, acc=76.5% | Val: loss=0.467, acc=85.7% | lr=0.000111
2025-11-24 07:17:47,736 [coscl.py] => Epoch 88/100 | Train: loss=0.938, acc=77.3% | Val: loss=0.463, acc=85.9% | lr=0.000111
2025-11-24 07:17:49,636 [coscl.py] => Epoch 89/100 | Train: loss=0.937, acc=76.9% | Val: loss=0.455, acc=86.4% | lr=0.000111
2025-11-24 07:17:51,316 [coscl.py] => Epoch 90/100 | Train: loss=0.924, acc=77.2% | Val: loss=0.459, acc=86.1% | lr=0.000111
2025-11-24 07:17:53,127 [coscl.py] => Epoch 91/100 | Train: loss=0.928, acc=78.0% | Val: loss=0.455, acc=86.2% | lr=0.000111
2025-11-24 07:17:54,860 [coscl.py] => Epoch 92/100 | Train: loss=0.935, acc=77.4% | Val: loss=0.459, acc=86.1% | lr=0.000037
2025-11-24 07:17:56,586 [coscl.py] => Epoch 93/100 | Train: loss=0.941, acc=77.5% | Val: loss=0.454, acc=86.2% | lr=0.000037
2025-11-24 07:17:58,768 [coscl.py] => Epoch 94/100 | Train: loss=0.939, acc=77.1% | Val: loss=0.456, acc=86.1% | lr=0.000037
2025-11-24 07:18:00,460 [coscl.py] => Epoch 95/100 | Train: loss=0.928, acc=77.7% | Val: loss=0.458, acc=86.3% | lr=0.000037
2025-11-24 07:18:02,240 [coscl.py] => Epoch 96/100 | Train: loss=0.929, acc=77.0% | Val: loss=0.459, acc=86.3% | lr=0.000037
2025-11-24 07:18:04,164 [coscl.py] => Epoch 97/100 | Train: loss=0.935, acc=77.4% | Val: loss=0.457, acc=86.3% | lr=0.000012
2025-11-24 07:18:05,981 [coscl.py] => Epoch 98/100 | Train: loss=0.930, acc=77.3% | Val: loss=0.457, acc=86.3% | lr=0.000012
2025-11-24 07:18:07,901 [coscl.py] => Epoch 99/100 | Train: loss=0.935, acc=77.0% | Val: loss=0.457, acc=86.3% | lr=0.000012
2025-11-24 07:18:09,669 [coscl.py] => Epoch 100/100 | Train: loss=0.932, acc=77.7% | Val: loss=0.455, acc=86.3% | lr=0.000012
2025-11-24 07:18:12,889 [trainer.py] => No NME accuracy.
2025-11-24 07:18:12,892 [trainer.py] => CNN: {'total': np.float64(58.0), '00-09': np.float64(61.3), '10-19': np.float64(54.7), 'old': np.float64(61.3), 'new': np.float64(54.7)}
2025-11-24 07:18:12,892 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0)]
2025-11-24 07:18:12,892 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1)]

2025-11-24 07:18:12,894 [trainer.py] => Average Accuracy (CNN): 65.35 

2025-11-24 07:18:12,895 [trainer.py] => All params: 773260
2025-11-24 07:18:12,895 [trainer.py] => Trainable params: 773260
2025-11-24 07:18:15,317 [coscl.py] => Epoch 1/100 | Train: loss=1.801, acc=43.0% | Val: loss=1.032, acc=65.9% | lr=0.001000
2025-11-24 07:18:17,102 [coscl.py] => Epoch 2/100 | Train: loss=1.407, acc=61.5% | Val: loss=0.847, acc=73.4% | lr=0.001000
2025-11-24 07:18:19,069 [coscl.py] => Epoch 3/100 | Train: loss=1.312, acc=65.5% | Val: loss=0.785, acc=75.6% | lr=0.001000
2025-11-24 07:18:20,773 [coscl.py] => Epoch 4/100 | Train: loss=1.260, acc=66.8% | Val: loss=0.781, acc=75.1% | lr=0.001000
2025-11-24 07:18:22,448 [coscl.py] => Epoch 5/100 | Train: loss=1.233, acc=68.4% | Val: loss=0.731, acc=76.9% | lr=0.001000
2025-11-24 07:18:24,222 [coscl.py] => Epoch 6/100 | Train: loss=1.205, acc=69.3% | Val: loss=0.721, acc=77.1% | lr=0.001000
2025-11-24 07:18:25,983 [coscl.py] => Epoch 7/100 | Train: loss=1.204, acc=69.3% | Val: loss=0.688, acc=78.1% | lr=0.001000
2025-11-24 07:18:27,761 [coscl.py] => Epoch 8/100 | Train: loss=1.189, acc=69.6% | Val: loss=0.669, acc=78.6% | lr=0.001000
2025-11-24 07:18:29,563 [coscl.py] => Epoch 9/100 | Train: loss=1.167, acc=70.9% | Val: loss=0.687, acc=78.7% | lr=0.001000
2025-11-24 07:18:31,272 [coscl.py] => Epoch 10/100 | Train: loss=1.168, acc=70.7% | Val: loss=0.666, acc=78.3% | lr=0.001000
2025-11-24 07:18:33,117 [coscl.py] => Epoch 11/100 | Train: loss=1.158, acc=70.8% | Val: loss=0.645, acc=79.1% | lr=0.001000
2025-11-24 07:18:34,860 [coscl.py] => Epoch 12/100 | Train: loss=1.161, acc=70.2% | Val: loss=0.650, acc=79.7% | lr=0.001000
2025-11-24 07:18:36,721 [coscl.py] => Epoch 13/100 | Train: loss=1.167, acc=70.7% | Val: loss=0.639, acc=79.9% | lr=0.001000
2025-11-24 07:18:38,431 [coscl.py] => Epoch 14/100 | Train: loss=1.151, acc=71.2% | Val: loss=0.634, acc=79.8% | lr=0.001000
2025-11-24 07:18:40,170 [coscl.py] => Epoch 15/100 | Train: loss=1.148, acc=71.7% | Val: loss=0.658, acc=78.7% | lr=0.001000
2025-11-24 07:18:41,896 [coscl.py] => Epoch 16/100 | Train: loss=1.136, acc=71.3% | Val: loss=0.659, acc=78.6% | lr=0.001000
2025-11-24 07:18:43,623 [coscl.py] => Epoch 17/100 | Train: loss=1.154, acc=71.4% | Val: loss=0.616, acc=80.1% | lr=0.001000
2025-11-24 07:18:45,447 [coscl.py] => Epoch 18/100 | Train: loss=1.140, acc=71.8% | Val: loss=0.603, acc=80.5% | lr=0.001000
2025-11-24 07:18:47,137 [coscl.py] => Epoch 19/100 | Train: loss=1.140, acc=71.9% | Val: loss=0.610, acc=81.0% | lr=0.001000
2025-11-24 07:18:48,926 [coscl.py] => Epoch 20/100 | Train: loss=1.129, acc=72.7% | Val: loss=0.614, acc=79.9% | lr=0.001000
2025-11-24 07:18:50,832 [coscl.py] => Epoch 21/100 | Train: loss=1.130, acc=72.4% | Val: loss=0.617, acc=80.1% | lr=0.001000
2025-11-24 07:18:52,534 [coscl.py] => Epoch 22/100 | Train: loss=1.127, acc=72.4% | Val: loss=0.598, acc=80.8% | lr=0.001000
2025-11-24 07:18:54,252 [coscl.py] => Epoch 23/100 | Train: loss=1.125, acc=72.3% | Val: loss=0.602, acc=81.0% | lr=0.001000
2025-11-24 07:18:56,181 [coscl.py] => Epoch 24/100 | Train: loss=1.111, acc=73.2% | Val: loss=0.608, acc=80.6% | lr=0.001000
2025-11-24 07:18:57,897 [coscl.py] => Epoch 25/100 | Train: loss=1.118, acc=71.8% | Val: loss=0.605, acc=80.3% | lr=0.001000
2025-11-24 07:18:59,589 [coscl.py] => Epoch 26/100 | Train: loss=1.110, acc=73.0% | Val: loss=0.602, acc=80.1% | lr=0.001000
2025-11-24 07:19:01,403 [coscl.py] => Epoch 27/100 | Train: loss=1.091, acc=74.6% | Val: loss=0.592, acc=80.5% | lr=0.001000
2025-11-24 07:19:03,126 [coscl.py] => Epoch 28/100 | Train: loss=1.114, acc=72.4% | Val: loss=0.595, acc=81.2% | lr=0.001000
2025-11-24 07:19:04,904 [coscl.py] => Epoch 29/100 | Train: loss=1.104, acc=73.2% | Val: loss=0.616, acc=80.8% | lr=0.001000
2025-11-24 07:19:06,836 [coscl.py] => Epoch 30/100 | Train: loss=1.126, acc=72.3% | Val: loss=0.589, acc=81.7% | lr=0.001000
2025-11-24 07:19:08,541 [coscl.py] => Epoch 31/100 | Train: loss=1.105, acc=73.0% | Val: loss=0.590, acc=81.5% | lr=0.001000
2025-11-24 07:19:10,739 [coscl.py] => Epoch 32/100 | Train: loss=1.106, acc=73.6% | Val: loss=0.600, acc=81.0% | lr=0.001000
2025-11-24 07:19:12,560 [coscl.py] => Epoch 33/100 | Train: loss=1.118, acc=72.5% | Val: loss=0.578, acc=81.3% | lr=0.001000
2025-11-24 07:19:14,246 [coscl.py] => Epoch 34/100 | Train: loss=1.101, acc=73.5% | Val: loss=0.586, acc=81.5% | lr=0.001000
2025-11-24 07:19:16,135 [coscl.py] => Epoch 35/100 | Train: loss=1.092, acc=73.8% | Val: loss=0.580, acc=82.1% | lr=0.001000
2025-11-24 07:19:17,853 [coscl.py] => Epoch 36/100 | Train: loss=1.102, acc=72.7% | Val: loss=0.579, acc=82.0% | lr=0.001000
2025-11-24 07:19:19,528 [coscl.py] => Epoch 37/100 | Train: loss=1.088, acc=74.3% | Val: loss=0.577, acc=81.7% | lr=0.001000
2025-11-24 07:19:21,282 [coscl.py] => Epoch 38/100 | Train: loss=1.111, acc=73.0% | Val: loss=0.571, acc=82.1% | lr=0.001000
2025-11-24 07:19:23,040 [coscl.py] => Epoch 39/100 | Train: loss=1.099, acc=74.2% | Val: loss=0.564, acc=81.9% | lr=0.001000
2025-11-24 07:19:24,972 [coscl.py] => Epoch 40/100 | Train: loss=1.107, acc=73.6% | Val: loss=0.582, acc=81.1% | lr=0.001000
2025-11-24 07:19:26,680 [coscl.py] => Epoch 41/100 | Train: loss=1.100, acc=73.3% | Val: loss=0.578, acc=81.6% | lr=0.001000
2025-11-24 07:19:28,419 [coscl.py] => Epoch 42/100 | Train: loss=1.093, acc=73.0% | Val: loss=0.565, acc=81.9% | lr=0.001000
2025-11-24 07:19:30,157 [coscl.py] => Epoch 43/100 | Train: loss=1.085, acc=73.4% | Val: loss=0.562, acc=81.7% | lr=0.001000
2025-11-24 07:19:31,896 [coscl.py] => Epoch 44/100 | Train: loss=1.089, acc=73.6% | Val: loss=0.566, acc=81.9% | lr=0.001000
2025-11-24 07:19:33,624 [coscl.py] => Epoch 45/100 | Train: loss=1.099, acc=73.4% | Val: loss=0.593, acc=81.3% | lr=0.001000
2025-11-24 07:19:35,332 [coscl.py] => Epoch 46/100 | Train: loss=1.077, acc=74.3% | Val: loss=0.556, acc=82.6% | lr=0.001000
2025-11-24 07:19:37,104 [coscl.py] => Epoch 47/100 | Train: loss=1.084, acc=74.6% | Val: loss=0.555, acc=82.8% | lr=0.001000
2025-11-24 07:19:38,980 [coscl.py] => Epoch 48/100 | Train: loss=1.083, acc=73.4% | Val: loss=0.539, acc=82.9% | lr=0.001000
2025-11-24 07:19:40,666 [coscl.py] => Epoch 49/100 | Train: loss=1.082, acc=74.4% | Val: loss=0.549, acc=82.7% | lr=0.001000
2025-11-24 07:19:42,453 [coscl.py] => Epoch 50/100 | Train: loss=1.100, acc=72.6% | Val: loss=0.558, acc=82.2% | lr=0.001000
2025-11-24 07:19:44,157 [coscl.py] => Epoch 51/100 | Train: loss=1.076, acc=73.4% | Val: loss=0.558, acc=82.7% | lr=0.001000
2025-11-24 07:19:45,859 [coscl.py] => Epoch 52/100 | Train: loss=1.077, acc=74.3% | Val: loss=0.546, acc=82.6% | lr=0.001000
2025-11-24 07:19:47,679 [coscl.py] => Epoch 53/100 | Train: loss=1.096, acc=73.7% | Val: loss=0.546, acc=82.5% | lr=0.001000
2025-11-24 07:19:49,371 [coscl.py] => Epoch 54/100 | Train: loss=1.052, acc=75.0% | Val: loss=0.533, acc=83.3% | lr=0.000333
2025-11-24 07:19:51,136 [coscl.py] => Epoch 55/100 | Train: loss=1.033, acc=74.9% | Val: loss=0.525, acc=83.5% | lr=0.000333
2025-11-24 07:19:52,917 [coscl.py] => Epoch 56/100 | Train: loss=1.042, acc=74.5% | Val: loss=0.533, acc=83.5% | lr=0.000333
2025-11-24 07:19:54,644 [coscl.py] => Epoch 57/100 | Train: loss=1.020, acc=74.9% | Val: loss=0.532, acc=83.2% | lr=0.000333
2025-11-24 07:19:56,434 [coscl.py] => Epoch 58/100 | Train: loss=1.025, acc=74.1% | Val: loss=0.524, acc=83.6% | lr=0.000333
2025-11-24 07:19:58,263 [coscl.py] => Epoch 59/100 | Train: loss=1.031, acc=74.6% | Val: loss=0.524, acc=83.5% | lr=0.000333
2025-11-24 07:20:00,081 [coscl.py] => Epoch 60/100 | Train: loss=1.023, acc=75.4% | Val: loss=0.536, acc=83.4% | lr=0.000333
2025-11-24 07:20:01,909 [coscl.py] => Epoch 61/100 | Train: loss=1.020, acc=75.2% | Val: loss=0.541, acc=83.4% | lr=0.000333
2025-11-24 07:20:03,661 [coscl.py] => Epoch 62/100 | Train: loss=1.018, acc=74.9% | Val: loss=0.523, acc=83.7% | lr=0.000333
2025-11-24 07:20:05,386 [coscl.py] => Epoch 63/100 | Train: loss=1.013, acc=75.5% | Val: loss=0.537, acc=83.4% | lr=0.000333
2025-11-24 07:20:07,215 [coscl.py] => Epoch 64/100 | Train: loss=1.006, acc=75.5% | Val: loss=0.523, acc=83.7% | lr=0.000333
2025-11-24 07:20:08,980 [coscl.py] => Epoch 65/100 | Train: loss=1.002, acc=74.9% | Val: loss=0.518, acc=83.8% | lr=0.000333
2025-11-24 07:20:10,878 [coscl.py] => Epoch 66/100 | Train: loss=1.023, acc=74.0% | Val: loss=0.527, acc=83.4% | lr=0.000333
2025-11-24 07:20:12,667 [coscl.py] => Epoch 67/100 | Train: loss=1.020, acc=75.0% | Val: loss=0.521, acc=83.5% | lr=0.000333
2025-11-24 07:20:14,401 [coscl.py] => Epoch 68/100 | Train: loss=0.994, acc=76.2% | Val: loss=0.528, acc=82.9% | lr=0.000333
2025-11-24 07:20:16,134 [coscl.py] => Epoch 69/100 | Train: loss=1.014, acc=74.5% | Val: loss=0.515, acc=83.9% | lr=0.000333
2025-11-24 07:20:18,119 [coscl.py] => Epoch 70/100 | Train: loss=1.006, acc=74.9% | Val: loss=0.518, acc=84.1% | lr=0.000333
2025-11-24 07:20:19,819 [coscl.py] => Epoch 71/100 | Train: loss=1.007, acc=75.5% | Val: loss=0.512, acc=83.9% | lr=0.000333
2025-11-24 07:20:21,543 [coscl.py] => Epoch 72/100 | Train: loss=1.018, acc=74.5% | Val: loss=0.521, acc=84.0% | lr=0.000333
2025-11-24 07:20:23,254 [coscl.py] => Epoch 73/100 | Train: loss=1.009, acc=76.2% | Val: loss=0.537, acc=83.3% | lr=0.000333
2025-11-24 07:20:25,038 [coscl.py] => Epoch 74/100 | Train: loss=1.002, acc=75.2% | Val: loss=0.519, acc=84.0% | lr=0.000333
2025-11-24 07:20:26,809 [coscl.py] => Epoch 75/100 | Train: loss=1.001, acc=74.9% | Val: loss=0.506, acc=84.6% | lr=0.000333
2025-11-24 07:20:28,519 [coscl.py] => Epoch 76/100 | Train: loss=1.011, acc=75.3% | Val: loss=0.509, acc=84.0% | lr=0.000333
2025-11-24 07:20:30,209 [coscl.py] => Epoch 77/100 | Train: loss=1.006, acc=75.9% | Val: loss=0.519, acc=84.1% | lr=0.000333
2025-11-24 07:20:31,963 [coscl.py] => Epoch 78/100 | Train: loss=1.000, acc=75.3% | Val: loss=0.525, acc=83.9% | lr=0.000333
2025-11-24 07:20:34,161 [coscl.py] => Epoch 79/100 | Train: loss=1.010, acc=75.4% | Val: loss=0.530, acc=83.6% | lr=0.000333
2025-11-24 07:20:35,886 [coscl.py] => Epoch 80/100 | Train: loss=1.002, acc=75.1% | Val: loss=0.527, acc=83.7% | lr=0.000333
2025-11-24 07:20:37,646 [coscl.py] => Epoch 81/100 | Train: loss=1.003, acc=75.4% | Val: loss=0.510, acc=84.4% | lr=0.000111
2025-11-24 07:20:39,381 [coscl.py] => Epoch 82/100 | Train: loss=0.985, acc=75.4% | Val: loss=0.509, acc=84.2% | lr=0.000111
2025-11-24 07:20:41,109 [coscl.py] => Epoch 83/100 | Train: loss=0.988, acc=75.5% | Val: loss=0.509, acc=84.4% | lr=0.000111
2025-11-24 07:20:42,968 [coscl.py] => Epoch 84/100 | Train: loss=0.995, acc=75.3% | Val: loss=0.513, acc=84.0% | lr=0.000111
2025-11-24 07:20:44,626 [coscl.py] => Epoch 85/100 | Train: loss=0.980, acc=76.3% | Val: loss=0.504, acc=84.5% | lr=0.000111
2025-11-24 07:20:46,341 [coscl.py] => Epoch 86/100 | Train: loss=0.976, acc=75.8% | Val: loss=0.506, acc=84.6% | lr=0.000111
2025-11-24 07:20:48,148 [coscl.py] => Epoch 87/100 | Train: loss=0.990, acc=75.0% | Val: loss=0.512, acc=84.5% | lr=0.000111
2025-11-24 07:20:49,831 [coscl.py] => Epoch 88/100 | Train: loss=0.986, acc=75.9% | Val: loss=0.506, acc=84.4% | lr=0.000111
2025-11-24 07:20:51,528 [coscl.py] => Epoch 89/100 | Train: loss=0.974, acc=76.1% | Val: loss=0.505, acc=84.3% | lr=0.000111
2025-11-24 07:20:53,270 [coscl.py] => Epoch 90/100 | Train: loss=0.964, acc=76.7% | Val: loss=0.502, acc=84.2% | lr=0.000111
2025-11-24 07:20:55,120 [coscl.py] => Epoch 91/100 | Train: loss=0.988, acc=75.8% | Val: loss=0.506, acc=84.2% | lr=0.000111
2025-11-24 07:20:56,805 [coscl.py] => Epoch 92/100 | Train: loss=0.978, acc=75.3% | Val: loss=0.499, acc=84.5% | lr=0.000111
2025-11-24 07:20:58,603 [coscl.py] => Epoch 93/100 | Train: loss=0.982, acc=75.6% | Val: loss=0.510, acc=84.2% | lr=0.000111
2025-11-24 07:21:00,389 [coscl.py] => Epoch 94/100 | Train: loss=0.981, acc=75.8% | Val: loss=0.502, acc=84.4% | lr=0.000111
2025-11-24 07:21:02,077 [coscl.py] => Epoch 95/100 | Train: loss=0.983, acc=75.4% | Val: loss=0.513, acc=84.3% | lr=0.000111
2025-11-24 07:21:04,098 [coscl.py] => Epoch 96/100 | Train: loss=0.964, acc=76.3% | Val: loss=0.500, acc=84.6% | lr=0.000111
2025-11-24 07:21:05,791 [coscl.py] => Epoch 97/100 | Train: loss=0.974, acc=76.0% | Val: loss=0.503, acc=84.4% | lr=0.000111
2025-11-24 07:21:07,471 [coscl.py] => Epoch 98/100 | Train: loss=0.973, acc=75.8% | Val: loss=0.502, acc=84.3% | lr=0.000037
2025-11-24 07:21:09,387 [coscl.py] => Epoch 99/100 | Train: loss=0.984, acc=75.4% | Val: loss=0.504, acc=84.2% | lr=0.000037
2025-11-24 07:21:11,551 [coscl.py] => Epoch 100/100 | Train: loss=0.972, acc=76.1% | Val: loss=0.502, acc=84.7% | lr=0.000037
2025-11-24 07:21:13,468 [trainer.py] => No NME accuracy.
2025-11-24 07:21:13,468 [trainer.py] => CNN: {'total': np.float64(51.67), '00-09': np.float64(55.9), '10-19': np.float64(47.9), '20-29': np.float64(51.2), 'old': np.float64(51.9), 'new': np.float64(51.2)}
2025-11-24 07:21:13,469 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67)]
2025-11-24 07:21:13,469 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4)]

2025-11-24 07:21:13,469 [trainer.py] => Average Accuracy (CNN): 60.79 

2025-11-24 07:21:13,469 [trainer.py] => All params: 773260
2025-11-24 07:21:13,470 [trainer.py] => Trainable params: 773260
2025-11-24 07:21:15,499 [coscl.py] => Epoch 1/100 | Train: loss=2.066, acc=32.0% | Val: loss=1.380, acc=54.1% | lr=0.001000
2025-11-24 07:21:17,485 [coscl.py] => Epoch 2/100 | Train: loss=1.729, acc=47.6% | Val: loss=1.215, acc=60.2% | lr=0.001000
2025-11-24 07:21:19,175 [coscl.py] => Epoch 3/100 | Train: loss=1.626, acc=52.6% | Val: loss=1.122, acc=64.6% | lr=0.001000
2025-11-24 07:21:20,912 [coscl.py] => Epoch 4/100 | Train: loss=1.601, acc=53.5% | Val: loss=1.078, acc=66.1% | lr=0.001000
2025-11-24 07:21:22,650 [coscl.py] => Epoch 5/100 | Train: loss=1.565, acc=55.3% | Val: loss=1.049, acc=66.8% | lr=0.001000
2025-11-24 07:21:24,478 [coscl.py] => Epoch 6/100 | Train: loss=1.536, acc=55.8% | Val: loss=1.017, acc=67.9% | lr=0.001000
2025-11-24 07:21:26,447 [coscl.py] => Epoch 7/100 | Train: loss=1.531, acc=56.4% | Val: loss=0.997, acc=69.1% | lr=0.001000
2025-11-24 07:21:28,224 [coscl.py] => Epoch 8/100 | Train: loss=1.523, acc=57.1% | Val: loss=1.001, acc=68.3% | lr=0.001000
2025-11-24 07:21:30,064 [coscl.py] => Epoch 9/100 | Train: loss=1.508, acc=57.7% | Val: loss=0.983, acc=68.5% | lr=0.001000
2025-11-24 07:21:31,812 [coscl.py] => Epoch 10/100 | Train: loss=1.482, acc=58.5% | Val: loss=0.979, acc=68.5% | lr=0.001000
2025-11-24 07:21:33,680 [coscl.py] => Epoch 11/100 | Train: loss=1.484, acc=58.3% | Val: loss=0.996, acc=68.5% | lr=0.001000
2025-11-24 07:21:35,469 [coscl.py] => Epoch 12/100 | Train: loss=1.491, acc=57.3% | Val: loss=0.950, acc=70.0% | lr=0.001000
2025-11-24 07:21:37,193 [coscl.py] => Epoch 13/100 | Train: loss=1.477, acc=58.9% | Val: loss=0.956, acc=69.6% | lr=0.001000
2025-11-24 07:21:39,013 [coscl.py] => Epoch 14/100 | Train: loss=1.478, acc=58.6% | Val: loss=0.988, acc=68.5% | lr=0.001000
2025-11-24 07:21:40,775 [coscl.py] => Epoch 15/100 | Train: loss=1.462, acc=59.2% | Val: loss=0.971, acc=68.6% | lr=0.001000
2025-11-24 07:21:42,508 [coscl.py] => Epoch 16/100 | Train: loss=1.469, acc=58.9% | Val: loss=0.974, acc=68.2% | lr=0.001000
2025-11-24 07:21:44,567 [coscl.py] => Epoch 17/100 | Train: loss=1.460, acc=58.9% | Val: loss=0.940, acc=70.1% | lr=0.001000
2025-11-24 07:21:46,555 [coscl.py] => Epoch 18/100 | Train: loss=1.468, acc=59.2% | Val: loss=0.939, acc=70.8% | lr=0.001000
2025-11-24 07:21:48,249 [coscl.py] => Epoch 19/100 | Train: loss=1.451, acc=60.0% | Val: loss=0.920, acc=70.9% | lr=0.001000
2025-11-24 07:21:50,005 [coscl.py] => Epoch 20/100 | Train: loss=1.445, acc=59.5% | Val: loss=0.932, acc=70.4% | lr=0.001000
2025-11-24 07:21:51,892 [coscl.py] => Epoch 21/100 | Train: loss=1.439, acc=58.9% | Val: loss=0.920, acc=70.9% | lr=0.001000
2025-11-24 07:21:53,679 [coscl.py] => Epoch 22/100 | Train: loss=1.451, acc=59.4% | Val: loss=0.914, acc=71.5% | lr=0.001000
2025-11-24 07:21:55,644 [coscl.py] => Epoch 23/100 | Train: loss=1.426, acc=60.4% | Val: loss=0.924, acc=70.5% | lr=0.001000
2025-11-24 07:21:57,390 [coscl.py] => Epoch 24/100 | Train: loss=1.432, acc=60.9% | Val: loss=0.895, acc=71.2% | lr=0.001000
2025-11-24 07:21:59,153 [coscl.py] => Epoch 25/100 | Train: loss=1.451, acc=59.4% | Val: loss=0.919, acc=70.7% | lr=0.001000
2025-11-24 07:22:00,999 [coscl.py] => Epoch 26/100 | Train: loss=1.442, acc=59.9% | Val: loss=0.907, acc=71.3% | lr=0.001000
2025-11-24 07:22:02,705 [coscl.py] => Epoch 27/100 | Train: loss=1.435, acc=59.7% | Val: loss=0.955, acc=69.2% | lr=0.001000
2025-11-24 07:22:04,490 [coscl.py] => Epoch 28/100 | Train: loss=1.444, acc=59.7% | Val: loss=0.915, acc=70.3% | lr=0.001000
2025-11-24 07:22:06,539 [coscl.py] => Epoch 29/100 | Train: loss=1.425, acc=60.7% | Val: loss=0.912, acc=70.6% | lr=0.001000
2025-11-24 07:22:08,245 [coscl.py] => Epoch 30/100 | Train: loss=1.426, acc=59.2% | Val: loss=0.903, acc=71.6% | lr=0.000333
2025-11-24 07:22:10,024 [coscl.py] => Epoch 31/100 | Train: loss=1.375, acc=62.2% | Val: loss=0.885, acc=72.0% | lr=0.000333
2025-11-24 07:22:12,705 [coscl.py] => Epoch 32/100 | Train: loss=1.378, acc=60.9% | Val: loss=0.887, acc=71.9% | lr=0.000333
2025-11-24 07:22:14,493 [coscl.py] => Epoch 33/100 | Train: loss=1.365, acc=61.8% | Val: loss=0.887, acc=71.6% | lr=0.000333
2025-11-24 07:22:16,584 [coscl.py] => Epoch 34/100 | Train: loss=1.354, acc=61.8% | Val: loss=0.880, acc=71.8% | lr=0.000333
2025-11-24 07:22:18,619 [coscl.py] => Epoch 35/100 | Train: loss=1.347, acc=62.3% | Val: loss=0.878, acc=71.9% | lr=0.000333
2025-11-24 07:22:20,437 [coscl.py] => Epoch 36/100 | Train: loss=1.353, acc=62.1% | Val: loss=0.871, acc=72.5% | lr=0.000333
2025-11-24 07:22:22,218 [coscl.py] => Epoch 37/100 | Train: loss=1.366, acc=60.9% | Val: loss=0.889, acc=71.2% | lr=0.000333
2025-11-24 07:22:24,137 [coscl.py] => Epoch 38/100 | Train: loss=1.341, acc=62.3% | Val: loss=0.864, acc=72.5% | lr=0.000333
2025-11-24 07:22:25,944 [coscl.py] => Epoch 39/100 | Train: loss=1.345, acc=61.8% | Val: loss=0.874, acc=72.2% | lr=0.000333
2025-11-24 07:22:27,758 [coscl.py] => Epoch 40/100 | Train: loss=1.346, acc=61.7% | Val: loss=0.867, acc=71.9% | lr=0.000333
2025-11-24 07:22:29,655 [coscl.py] => Epoch 41/100 | Train: loss=1.343, acc=62.0% | Val: loss=0.880, acc=72.4% | lr=0.000333
2025-11-24 07:22:31,430 [coscl.py] => Epoch 42/100 | Train: loss=1.344, acc=62.3% | Val: loss=0.870, acc=72.2% | lr=0.000333
2025-11-24 07:22:33,126 [coscl.py] => Epoch 43/100 | Train: loss=1.342, acc=61.7% | Val: loss=0.872, acc=72.4% | lr=0.000333
2025-11-24 07:22:34,900 [coscl.py] => Epoch 44/100 | Train: loss=1.332, acc=62.0% | Val: loss=0.866, acc=72.6% | lr=0.000111
2025-11-24 07:22:36,765 [coscl.py] => Epoch 45/100 | Train: loss=1.339, acc=62.0% | Val: loss=0.875, acc=72.4% | lr=0.000111
2025-11-24 07:22:38,515 [coscl.py] => Epoch 46/100 | Train: loss=1.325, acc=62.0% | Val: loss=0.876, acc=72.2% | lr=0.000111
2025-11-24 07:22:40,316 [coscl.py] => Epoch 47/100 | Train: loss=1.329, acc=61.4% | Val: loss=0.875, acc=72.3% | lr=0.000111
2025-11-24 07:22:42,246 [coscl.py] => Epoch 48/100 | Train: loss=1.332, acc=61.5% | Val: loss=0.865, acc=72.7% | lr=0.000111
2025-11-24 07:22:43,936 [coscl.py] => Epoch 49/100 | Train: loss=1.323, acc=62.2% | Val: loss=0.867, acc=72.5% | lr=0.000037
2025-11-24 07:22:45,673 [coscl.py] => Epoch 50/100 | Train: loss=1.325, acc=62.2% | Val: loss=0.864, acc=72.6% | lr=0.000037
2025-11-24 07:22:47,661 [coscl.py] => Epoch 51/100 | Train: loss=1.323, acc=61.8% | Val: loss=0.866, acc=72.8% | lr=0.000037
2025-11-24 07:22:49,378 [coscl.py] => Epoch 52/100 | Train: loss=1.329, acc=62.0% | Val: loss=0.868, acc=72.7% | lr=0.000037
2025-11-24 07:22:51,485 [coscl.py] => Epoch 53/100 | Train: loss=1.309, acc=62.2% | Val: loss=0.870, acc=72.4% | lr=0.000037
2025-11-24 07:22:53,228 [coscl.py] => Epoch 54/100 | Train: loss=1.313, acc=63.2% | Val: loss=0.868, acc=72.6% | lr=0.000012
2025-11-24 07:22:54,902 [coscl.py] => Epoch 55/100 | Train: loss=1.311, acc=62.7% | Val: loss=0.866, acc=72.6% | lr=0.000012
2025-11-24 07:22:56,867 [coscl.py] => Epoch 56/100 | Train: loss=1.325, acc=62.3% | Val: loss=0.864, acc=72.6% | lr=0.000012
2025-11-24 07:22:58,719 [coscl.py] => Epoch 57/100 | Train: loss=1.319, acc=61.3% | Val: loss=0.866, acc=72.6% | lr=0.000012
2025-11-24 07:23:00,443 [coscl.py] => Epoch 58/100 | Train: loss=1.305, acc=62.6% | Val: loss=0.866, acc=72.6% | lr=0.000012
2025-11-24 07:23:02,468 [coscl.py] => Epoch 59/100 | Train: loss=1.306, acc=61.9% | Val: loss=0.865, acc=72.6% | lr=0.000004
2025-11-24 07:23:04,236 [coscl.py] => Epoch 60/100 | Train: loss=1.307, acc=62.2% | Val: loss=0.865, acc=72.6% | lr=0.000004
2025-11-24 07:23:06,077 [coscl.py] => Epoch 61/100 | Train: loss=1.324, acc=62.1% | Val: loss=0.865, acc=72.7% | lr=0.000004
2025-11-24 07:23:07,840 [coscl.py] => Epoch 62/100 | Train: loss=1.321, acc=62.4% | Val: loss=0.866, acc=72.7% | lr=0.000004
2025-11-24 07:23:09,537 [coscl.py] => Epoch 63/100 | Train: loss=1.326, acc=61.7% | Val: loss=0.866, acc=72.7% | lr=0.000004
2025-11-24 07:23:11,651 [coscl.py] => Epoch 64/100 | Train: loss=1.309, acc=62.8% | Val: loss=0.866, acc=72.6% | lr=0.000001
2025-11-24 07:23:13,365 [coscl.py] => Epoch 65/100 | Train: loss=1.316, acc=62.4% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:15,127 [coscl.py] => Epoch 66/100 | Train: loss=1.314, acc=62.5% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:16,968 [coscl.py] => Epoch 67/100 | Train: loss=1.299, acc=63.2% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:18,672 [coscl.py] => Epoch 68/100 | Train: loss=1.298, acc=63.2% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:18,672 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:20,421 [coscl.py] => Epoch 69/100 | Train: loss=1.320, acc=62.0% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:20,422 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:22,320 [coscl.py] => Epoch 70/100 | Train: loss=1.321, acc=62.1% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:22,320 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:24,009 [coscl.py] => Epoch 71/100 | Train: loss=1.331, acc=61.6% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:24,009 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:25,762 [coscl.py] => Epoch 72/100 | Train: loss=1.307, acc=62.5% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:25,763 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:27,622 [coscl.py] => Epoch 73/100 | Train: loss=1.320, acc=62.1% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:27,623 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:29,343 [coscl.py] => Epoch 74/100 | Train: loss=1.303, acc=63.0% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:29,343 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:31,406 [coscl.py] => Epoch 75/100 | Train: loss=1.331, acc=61.5% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:31,407 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:33,281 [coscl.py] => Epoch 76/100 | Train: loss=1.307, acc=62.6% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:33,282 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:35,087 [coscl.py] => Epoch 77/100 | Train: loss=1.309, acc=62.1% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:35,087 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:37,009 [coscl.py] => Epoch 78/100 | Train: loss=1.309, acc=62.5% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:37,009 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:38,767 [coscl.py] => Epoch 79/100 | Train: loss=1.303, acc=63.2% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:23:38,768 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:40,510 [coscl.py] => Epoch 80/100 | Train: loss=1.306, acc=63.1% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:40,511 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:42,497 [coscl.py] => Epoch 81/100 | Train: loss=1.320, acc=61.9% | Val: loss=0.864, acc=72.7% | lr=0.000001
2025-11-24 07:23:42,497 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:44,178 [coscl.py] => Epoch 82/100 | Train: loss=1.322, acc=62.2% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:44,178 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:45,867 [coscl.py] => Epoch 83/100 | Train: loss=1.301, acc=62.8% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:45,868 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:47,564 [coscl.py] => Epoch 84/100 | Train: loss=1.307, acc=63.0% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:47,565 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:49,609 [coscl.py] => Epoch 85/100 | Train: loss=1.305, acc=62.3% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:49,610 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:51,328 [coscl.py] => Epoch 86/100 | Train: loss=1.304, acc=62.7% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:51,328 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:53,090 [coscl.py] => Epoch 87/100 | Train: loss=1.315, acc=62.0% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:53,090 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:54,893 [coscl.py] => Epoch 88/100 | Train: loss=1.307, acc=62.7% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:23:54,894 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:56,609 [coscl.py] => Epoch 89/100 | Train: loss=1.300, acc=62.7% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:56,610 [coscl.py] => Learning rate reached minimum
2025-11-24 07:23:58,299 [coscl.py] => Epoch 90/100 | Train: loss=1.306, acc=62.9% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:23:58,299 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:00,372 [coscl.py] => Epoch 91/100 | Train: loss=1.305, acc=62.7% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:24:00,373 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:02,072 [coscl.py] => Epoch 92/100 | Train: loss=1.328, acc=61.5% | Val: loss=0.865, acc=72.6% | lr=0.000001
2025-11-24 07:24:02,072 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:03,959 [coscl.py] => Epoch 93/100 | Train: loss=1.319, acc=61.9% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:24:03,960 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:05,840 [coscl.py] => Epoch 94/100 | Train: loss=1.314, acc=62.1% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:24:05,840 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:07,531 [coscl.py] => Epoch 95/100 | Train: loss=1.326, acc=61.9% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:24:07,532 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:09,807 [coscl.py] => Epoch 96/100 | Train: loss=1.319, acc=62.9% | Val: loss=0.864, acc=72.7% | lr=0.000001
2025-11-24 07:24:09,807 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:11,805 [coscl.py] => Epoch 97/100 | Train: loss=1.306, acc=62.1% | Val: loss=0.864, acc=72.6% | lr=0.000001
2025-11-24 07:24:11,806 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:13,579 [coscl.py] => Epoch 98/100 | Train: loss=1.312, acc=62.5% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:24:13,580 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:15,372 [coscl.py] => Epoch 99/100 | Train: loss=1.312, acc=62.8% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:24:15,373 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:17,192 [coscl.py] => Epoch 100/100 | Train: loss=1.298, acc=62.9% | Val: loss=0.865, acc=72.7% | lr=0.000001
2025-11-24 07:24:17,192 [coscl.py] => Learning rate reached minimum
2025-11-24 07:24:19,189 [trainer.py] => No NME accuracy.
2025-11-24 07:24:19,189 [trainer.py] => CNN: {'total': np.float64(42.95), '00-09': np.float64(54.5), '10-19': np.float64(44.3), '20-29': np.float64(51.1), '30-39': np.float64(21.9), 'old': np.float64(49.97), 'new': np.float64(21.9)}
2025-11-24 07:24:19,189 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95)]
2025-11-24 07:24:19,189 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92)]

2025-11-24 07:24:19,189 [trainer.py] => Average Accuracy (CNN): 56.33 

2025-11-24 07:24:19,189 [trainer.py] => All params: 773260
2025-11-24 07:24:19,190 [trainer.py] => Trainable params: 773260
2025-11-24 07:24:21,020 [coscl.py] => Epoch 1/100 | Train: loss=2.096, acc=33.8% | Val: loss=1.245, acc=60.8% | lr=0.001000
2025-11-24 07:24:22,968 [coscl.py] => Epoch 2/100 | Train: loss=1.705, acc=52.8% | Val: loss=1.060, acc=66.6% | lr=0.001000
2025-11-24 07:24:24,626 [coscl.py] => Epoch 3/100 | Train: loss=1.590, acc=56.9% | Val: loss=0.997, acc=69.3% | lr=0.001000
2025-11-24 07:24:26,420 [coscl.py] => Epoch 4/100 | Train: loss=1.544, acc=58.6% | Val: loss=0.969, acc=69.4% | lr=0.001000
2025-11-24 07:24:28,249 [coscl.py] => Epoch 5/100 | Train: loss=1.513, acc=60.4% | Val: loss=0.938, acc=71.1% | lr=0.001000
2025-11-24 07:24:29,962 [coscl.py] => Epoch 6/100 | Train: loss=1.488, acc=60.5% | Val: loss=0.927, acc=71.2% | lr=0.001000
2025-11-24 07:24:31,710 [coscl.py] => Epoch 7/100 | Train: loss=1.458, acc=61.5% | Val: loss=0.896, acc=71.4% | lr=0.001000
2025-11-24 07:24:33,863 [coscl.py] => Epoch 8/100 | Train: loss=1.443, acc=61.7% | Val: loss=0.885, acc=72.5% | lr=0.001000
2025-11-24 07:24:35,582 [coscl.py] => Epoch 9/100 | Train: loss=1.455, acc=61.0% | Val: loss=0.867, acc=72.5% | lr=0.001000
2025-11-24 07:24:37,398 [coscl.py] => Epoch 10/100 | Train: loss=1.418, acc=62.0% | Val: loss=0.858, acc=73.6% | lr=0.001000
2025-11-24 07:24:39,225 [coscl.py] => Epoch 11/100 | Train: loss=1.412, acc=62.8% | Val: loss=0.863, acc=72.6% | lr=0.001000
2025-11-24 07:24:40,934 [coscl.py] => Epoch 12/100 | Train: loss=1.407, acc=62.9% | Val: loss=0.852, acc=73.0% | lr=0.001000
2025-11-24 07:24:43,009 [coscl.py] => Epoch 13/100 | Train: loss=1.393, acc=64.2% | Val: loss=0.836, acc=73.5% | lr=0.001000
2025-11-24 07:24:44,784 [coscl.py] => Epoch 14/100 | Train: loss=1.393, acc=62.6% | Val: loss=0.829, acc=74.0% | lr=0.001000
2025-11-24 07:24:46,608 [coscl.py] => Epoch 15/100 | Train: loss=1.383, acc=64.0% | Val: loss=0.852, acc=73.6% | lr=0.001000
2025-11-24 07:24:48,771 [coscl.py] => Epoch 16/100 | Train: loss=1.394, acc=63.7% | Val: loss=0.859, acc=72.3% | lr=0.001000
2025-11-24 07:24:50,563 [coscl.py] => Epoch 17/100 | Train: loss=1.388, acc=63.2% | Val: loss=0.875, acc=71.6% | lr=0.001000
2025-11-24 07:24:52,318 [coscl.py] => Epoch 18/100 | Train: loss=1.391, acc=63.6% | Val: loss=0.815, acc=74.8% | lr=0.001000
2025-11-24 07:24:54,139 [coscl.py] => Epoch 19/100 | Train: loss=1.380, acc=64.5% | Val: loss=0.869, acc=71.9% | lr=0.001000
2025-11-24 07:24:55,817 [coscl.py] => Epoch 20/100 | Train: loss=1.372, acc=63.6% | Val: loss=0.814, acc=74.4% | lr=0.001000
2025-11-24 07:24:57,615 [coscl.py] => Epoch 21/100 | Train: loss=1.387, acc=63.4% | Val: loss=0.810, acc=74.2% | lr=0.001000
2025-11-24 07:24:59,388 [coscl.py] => Epoch 22/100 | Train: loss=1.376, acc=63.8% | Val: loss=0.808, acc=74.6% | lr=0.001000
2025-11-24 07:25:01,122 [coscl.py] => Epoch 23/100 | Train: loss=1.358, acc=64.1% | Val: loss=0.798, acc=75.2% | lr=0.001000
2025-11-24 07:25:03,077 [coscl.py] => Epoch 24/100 | Train: loss=1.355, acc=64.3% | Val: loss=0.831, acc=72.9% | lr=0.001000
2025-11-24 07:25:04,768 [coscl.py] => Epoch 25/100 | Train: loss=1.382, acc=63.4% | Val: loss=0.820, acc=74.9% | lr=0.001000
2025-11-24 07:25:06,497 [coscl.py] => Epoch 26/100 | Train: loss=1.374, acc=63.7% | Val: loss=0.811, acc=74.6% | lr=0.001000
2025-11-24 07:25:08,374 [coscl.py] => Epoch 27/100 | Train: loss=1.351, acc=63.6% | Val: loss=0.809, acc=75.2% | lr=0.001000
2025-11-24 07:25:10,245 [coscl.py] => Epoch 28/100 | Train: loss=1.352, acc=64.6% | Val: loss=0.818, acc=74.6% | lr=0.001000
2025-11-24 07:25:12,132 [coscl.py] => Epoch 29/100 | Train: loss=1.317, acc=65.0% | Val: loss=0.797, acc=74.5% | lr=0.000333
2025-11-24 07:25:13,927 [coscl.py] => Epoch 30/100 | Train: loss=1.315, acc=64.9% | Val: loss=0.783, acc=75.6% | lr=0.000333
2025-11-24 07:25:15,685 [coscl.py] => Epoch 31/100 | Train: loss=1.290, acc=65.3% | Val: loss=0.798, acc=75.1% | lr=0.000333
2025-11-24 07:25:17,402 [coscl.py] => Epoch 32/100 | Train: loss=1.291, acc=65.1% | Val: loss=0.791, acc=75.3% | lr=0.000333
2025-11-24 07:25:19,177 [coscl.py] => Epoch 33/100 | Train: loss=1.286, acc=65.6% | Val: loss=0.809, acc=74.0% | lr=0.000333
2025-11-24 07:25:20,983 [coscl.py] => Epoch 34/100 | Train: loss=1.290, acc=65.2% | Val: loss=0.782, acc=75.4% | lr=0.000333
2025-11-24 07:25:23,236 [coscl.py] => Epoch 35/100 | Train: loss=1.269, acc=65.7% | Val: loss=0.782, acc=75.3% | lr=0.000333
2025-11-24 07:25:25,102 [coscl.py] => Epoch 36/100 | Train: loss=1.280, acc=65.4% | Val: loss=0.783, acc=75.4% | lr=0.000333
2025-11-24 07:25:26,998 [coscl.py] => Epoch 37/100 | Train: loss=1.293, acc=64.3% | Val: loss=0.787, acc=75.4% | lr=0.000333
2025-11-24 07:25:28,791 [coscl.py] => Epoch 38/100 | Train: loss=1.273, acc=65.8% | Val: loss=0.784, acc=75.2% | lr=0.000333
2025-11-24 07:25:30,470 [coscl.py] => Epoch 39/100 | Train: loss=1.283, acc=64.7% | Val: loss=0.809, acc=74.0% | lr=0.000333
2025-11-24 07:25:32,428 [coscl.py] => Epoch 40/100 | Train: loss=1.288, acc=64.7% | Val: loss=0.786, acc=75.6% | lr=0.000111
2025-11-24 07:25:34,151 [coscl.py] => Epoch 41/100 | Train: loss=1.276, acc=64.9% | Val: loss=0.780, acc=75.5% | lr=0.000111
2025-11-24 07:25:35,885 [coscl.py] => Epoch 42/100 | Train: loss=1.257, acc=66.1% | Val: loss=0.775, acc=76.0% | lr=0.000111
2025-11-24 07:25:37,742 [coscl.py] => Epoch 43/100 | Train: loss=1.253, acc=65.4% | Val: loss=0.787, acc=75.2% | lr=0.000111
2025-11-24 07:25:39,459 [coscl.py] => Epoch 44/100 | Train: loss=1.254, acc=66.8% | Val: loss=0.783, acc=75.7% | lr=0.000111
2025-11-24 07:25:41,143 [coscl.py] => Epoch 45/100 | Train: loss=1.266, acc=65.7% | Val: loss=0.786, acc=75.4% | lr=0.000111
2025-11-24 07:25:43,141 [coscl.py] => Epoch 46/100 | Train: loss=1.251, acc=66.3% | Val: loss=0.778, acc=75.5% | lr=0.000111
2025-11-24 07:25:44,883 [coscl.py] => Epoch 47/100 | Train: loss=1.247, acc=66.1% | Val: loss=0.776, acc=75.7% | lr=0.000111
2025-11-24 07:25:46,578 [coscl.py] => Epoch 48/100 | Train: loss=1.240, acc=66.6% | Val: loss=0.773, acc=75.8% | lr=0.000037
2025-11-24 07:25:48,261 [coscl.py] => Epoch 49/100 | Train: loss=1.254, acc=66.3% | Val: loss=0.776, acc=75.6% | lr=0.000037
2025-11-24 07:25:49,972 [coscl.py] => Epoch 50/100 | Train: loss=1.251, acc=65.7% | Val: loss=0.773, acc=75.8% | lr=0.000037
2025-11-24 07:25:51,684 [coscl.py] => Epoch 51/100 | Train: loss=1.246, acc=65.5% | Val: loss=0.775, acc=75.7% | lr=0.000037
2025-11-24 07:25:53,449 [coscl.py] => Epoch 52/100 | Train: loss=1.230, acc=66.7% | Val: loss=0.772, acc=75.8% | lr=0.000037
2025-11-24 07:25:55,158 [coscl.py] => Epoch 53/100 | Train: loss=1.239, acc=66.8% | Val: loss=0.772, acc=75.8% | lr=0.000037
2025-11-24 07:25:56,953 [coscl.py] => Epoch 54/100 | Train: loss=1.242, acc=66.6% | Val: loss=0.768, acc=75.9% | lr=0.000037
2025-11-24 07:25:58,800 [coscl.py] => Epoch 55/100 | Train: loss=1.233, acc=66.5% | Val: loss=0.773, acc=75.7% | lr=0.000037
2025-11-24 07:26:00,649 [coscl.py] => Epoch 56/100 | Train: loss=1.230, acc=67.2% | Val: loss=0.770, acc=75.9% | lr=0.000037
2025-11-24 07:26:02,564 [coscl.py] => Epoch 57/100 | Train: loss=1.245, acc=65.8% | Val: loss=0.775, acc=75.7% | lr=0.000037
2025-11-24 07:26:04,289 [coscl.py] => Epoch 58/100 | Train: loss=1.247, acc=65.7% | Val: loss=0.771, acc=75.8% | lr=0.000037
2025-11-24 07:26:06,166 [coscl.py] => Epoch 59/100 | Train: loss=1.242, acc=66.1% | Val: loss=0.774, acc=75.9% | lr=0.000037
2025-11-24 07:26:08,020 [coscl.py] => Epoch 60/100 | Train: loss=1.240, acc=65.8% | Val: loss=0.775, acc=75.6% | lr=0.000012
2025-11-24 07:26:09,700 [coscl.py] => Epoch 61/100 | Train: loss=1.249, acc=65.6% | Val: loss=0.772, acc=75.9% | lr=0.000012
2025-11-24 07:26:14,805 [coscl.py] => Epoch 62/100 | Train: loss=1.248, acc=65.4% | Val: loss=0.771, acc=75.9% | lr=0.000012
2025-11-24 07:26:16,713 [coscl.py] => Epoch 63/100 | Train: loss=1.230, acc=66.3% | Val: loss=0.772, acc=75.9% | lr=0.000012
2025-11-24 07:26:18,438 [coscl.py] => Epoch 64/100 | Train: loss=1.239, acc=65.9% | Val: loss=0.773, acc=75.9% | lr=0.000012
2025-11-24 07:26:20,276 [coscl.py] => Epoch 65/100 | Train: loss=1.241, acc=66.0% | Val: loss=0.771, acc=75.9% | lr=0.000004
2025-11-24 07:26:22,087 [coscl.py] => Epoch 66/100 | Train: loss=1.239, acc=66.0% | Val: loss=0.771, acc=75.8% | lr=0.000004
2025-11-24 07:26:23,872 [coscl.py] => Epoch 67/100 | Train: loss=1.243, acc=65.5% | Val: loss=0.771, acc=75.9% | lr=0.000004
2025-11-24 07:26:25,521 [coscl.py] => Epoch 68/100 | Train: loss=1.239, acc=66.1% | Val: loss=0.772, acc=75.8% | lr=0.000004
2025-11-24 07:26:27,256 [coscl.py] => Epoch 69/100 | Train: loss=1.238, acc=65.7% | Val: loss=0.772, acc=75.8% | lr=0.000004
2025-11-24 07:26:29,064 [coscl.py] => Epoch 70/100 | Train: loss=1.261, acc=65.2% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:30,780 [coscl.py] => Epoch 71/100 | Train: loss=1.242, acc=66.1% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:32,840 [coscl.py] => Epoch 72/100 | Train: loss=1.235, acc=65.8% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:35,195 [coscl.py] => Epoch 73/100 | Train: loss=1.254, acc=64.9% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:36,891 [coscl.py] => Epoch 74/100 | Train: loss=1.233, acc=66.1% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:36,892 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:38,650 [coscl.py] => Epoch 75/100 | Train: loss=1.240, acc=65.5% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:38,651 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:40,480 [coscl.py] => Epoch 76/100 | Train: loss=1.237, acc=66.3% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:40,480 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:42,200 [coscl.py] => Epoch 77/100 | Train: loss=1.237, acc=65.5% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:26:42,201 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:43,971 [coscl.py] => Epoch 78/100 | Train: loss=1.229, acc=66.2% | Val: loss=0.771, acc=75.8% | lr=0.000001
2025-11-24 07:26:43,971 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:45,744 [coscl.py] => Epoch 79/100 | Train: loss=1.252, acc=65.9% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:26:45,744 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:47,398 [coscl.py] => Epoch 80/100 | Train: loss=1.244, acc=65.6% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:26:47,398 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:49,096 [coscl.py] => Epoch 81/100 | Train: loss=1.245, acc=65.2% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:26:49,096 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:50,921 [coscl.py] => Epoch 82/100 | Train: loss=1.235, acc=66.0% | Val: loss=0.771, acc=75.8% | lr=0.000001
2025-11-24 07:26:50,921 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:52,616 [coscl.py] => Epoch 83/100 | Train: loss=1.231, acc=66.8% | Val: loss=0.772, acc=75.9% | lr=0.000001
2025-11-24 07:26:52,616 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:54,336 [coscl.py] => Epoch 84/100 | Train: loss=1.236, acc=66.5% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:26:54,336 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:56,167 [coscl.py] => Epoch 85/100 | Train: loss=1.235, acc=66.0% | Val: loss=0.772, acc=75.9% | lr=0.000001
2025-11-24 07:26:56,167 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:57,894 [coscl.py] => Epoch 86/100 | Train: loss=1.238, acc=66.1% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:26:57,894 [coscl.py] => Learning rate reached minimum
2025-11-24 07:26:59,608 [coscl.py] => Epoch 87/100 | Train: loss=1.235, acc=66.8% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:26:59,609 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:01,428 [coscl.py] => Epoch 88/100 | Train: loss=1.234, acc=66.5% | Val: loss=0.771, acc=75.8% | lr=0.000001
2025-11-24 07:27:01,429 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:03,109 [coscl.py] => Epoch 89/100 | Train: loss=1.241, acc=65.9% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:27:03,110 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:04,899 [coscl.py] => Epoch 90/100 | Train: loss=1.246, acc=65.6% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:27:04,899 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:06,661 [coscl.py] => Epoch 91/100 | Train: loss=1.219, acc=67.0% | Val: loss=0.771, acc=75.8% | lr=0.000001
2025-11-24 07:27:06,662 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:08,437 [coscl.py] => Epoch 92/100 | Train: loss=1.233, acc=65.8% | Val: loss=0.772, acc=75.9% | lr=0.000001
2025-11-24 07:27:08,438 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:10,386 [coscl.py] => Epoch 93/100 | Train: loss=1.227, acc=66.7% | Val: loss=0.772, acc=75.9% | lr=0.000001
2025-11-24 07:27:10,387 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:12,225 [coscl.py] => Epoch 94/100 | Train: loss=1.236, acc=66.0% | Val: loss=0.772, acc=75.9% | lr=0.000001
2025-11-24 07:27:12,226 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:14,075 [coscl.py] => Epoch 95/100 | Train: loss=1.228, acc=67.1% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:27:14,076 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:15,855 [coscl.py] => Epoch 96/100 | Train: loss=1.225, acc=66.1% | Val: loss=0.772, acc=75.9% | lr=0.000001
2025-11-24 07:27:15,855 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:17,692 [coscl.py] => Epoch 97/100 | Train: loss=1.250, acc=65.2% | Val: loss=0.771, acc=75.8% | lr=0.000001
2025-11-24 07:27:17,692 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:19,371 [coscl.py] => Epoch 98/100 | Train: loss=1.244, acc=66.1% | Val: loss=0.772, acc=75.8% | lr=0.000001
2025-11-24 07:27:19,371 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:21,326 [coscl.py] => Epoch 99/100 | Train: loss=1.240, acc=66.3% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:27:21,326 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:23,008 [coscl.py] => Epoch 100/100 | Train: loss=1.241, acc=65.4% | Val: loss=0.771, acc=75.9% | lr=0.000001
2025-11-24 07:27:23,009 [coscl.py] => Learning rate reached minimum
2025-11-24 07:27:25,164 [trainer.py] => No NME accuracy.
2025-11-24 07:27:25,164 [trainer.py] => CNN: {'total': np.float64(38.3), '00-09': np.float64(55.1), '10-19': np.float64(42.1), '20-29': np.float64(48.0), '30-39': np.float64(19.6), '40-49': np.float64(26.7), 'old': np.float64(41.2), 'new': np.float64(26.7)}
2025-11-24 07:27:25,164 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95), np.float64(38.3)]
2025-11-24 07:27:25,164 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92), np.float64(75.02)]

2025-11-24 07:27:25,164 [trainer.py] => Average Accuracy (CNN): 52.724000000000004 

2025-11-24 07:27:25,165 [trainer.py] => All params: 773260
2025-11-24 07:27:25,165 [trainer.py] => Trainable params: 773260
2025-11-24 07:27:26,976 [coscl.py] => Epoch 1/100 | Train: loss=1.963, acc=38.1% | Val: loss=1.137, acc=59.3% | lr=0.001000
2025-11-24 07:27:28,714 [coscl.py] => Epoch 2/100 | Train: loss=1.612, acc=53.0% | Val: loss=0.999, acc=65.9% | lr=0.001000
2025-11-24 07:27:30,435 [coscl.py] => Epoch 3/100 | Train: loss=1.508, acc=56.1% | Val: loss=0.943, acc=66.9% | lr=0.001000
2025-11-24 07:27:32,245 [coscl.py] => Epoch 4/100 | Train: loss=1.448, acc=58.1% | Val: loss=0.933, acc=67.5% | lr=0.001000
2025-11-24 07:27:34,157 [coscl.py] => Epoch 5/100 | Train: loss=1.404, acc=59.4% | Val: loss=0.895, acc=68.8% | lr=0.001000
2025-11-24 07:27:35,877 [coscl.py] => Epoch 6/100 | Train: loss=1.385, acc=58.9% | Val: loss=0.884, acc=69.2% | lr=0.001000
2025-11-24 07:27:37,630 [coscl.py] => Epoch 7/100 | Train: loss=1.361, acc=60.0% | Val: loss=0.871, acc=69.3% | lr=0.001000
2025-11-24 07:27:39,524 [coscl.py] => Epoch 8/100 | Train: loss=1.362, acc=60.4% | Val: loss=0.858, acc=70.6% | lr=0.001000
2025-11-24 07:27:41,340 [coscl.py] => Epoch 9/100 | Train: loss=1.322, acc=61.0% | Val: loss=0.850, acc=69.8% | lr=0.001000
2025-11-24 07:27:43,040 [coscl.py] => Epoch 10/100 | Train: loss=1.335, acc=60.2% | Val: loss=0.869, acc=69.1% | lr=0.001000
2025-11-24 07:27:45,082 [coscl.py] => Epoch 11/100 | Train: loss=1.324, acc=61.1% | Val: loss=0.857, acc=68.7% | lr=0.001000
2025-11-24 07:27:46,819 [coscl.py] => Epoch 12/100 | Train: loss=1.313, acc=61.3% | Val: loss=0.852, acc=69.1% | lr=0.001000
2025-11-24 07:27:48,746 [coscl.py] => Epoch 13/100 | Train: loss=1.322, acc=60.9% | Val: loss=0.838, acc=69.9% | lr=0.001000
2025-11-24 07:27:50,756 [coscl.py] => Epoch 14/100 | Train: loss=1.316, acc=60.9% | Val: loss=0.812, acc=71.8% | lr=0.001000
2025-11-24 07:27:52,585 [coscl.py] => Epoch 15/100 | Train: loss=1.305, acc=61.5% | Val: loss=0.815, acc=71.1% | lr=0.001000
2025-11-24 07:27:54,276 [coscl.py] => Epoch 16/100 | Train: loss=1.292, acc=62.6% | Val: loss=0.821, acc=71.1% | lr=0.001000
2025-11-24 07:27:56,478 [coscl.py] => Epoch 17/100 | Train: loss=1.275, acc=61.7% | Val: loss=0.821, acc=70.8% | lr=0.001000
2025-11-24 07:27:58,320 [coscl.py] => Epoch 18/100 | Train: loss=1.286, acc=61.5% | Val: loss=0.808, acc=71.3% | lr=0.001000
2025-11-24 07:28:00,091 [coscl.py] => Epoch 19/100 | Train: loss=1.281, acc=61.6% | Val: loss=0.808, acc=71.2% | lr=0.001000
2025-11-24 07:28:01,808 [coscl.py] => Epoch 20/100 | Train: loss=1.280, acc=61.9% | Val: loss=0.798, acc=72.7% | lr=0.001000
2025-11-24 07:28:03,664 [coscl.py] => Epoch 21/100 | Train: loss=1.285, acc=62.9% | Val: loss=0.786, acc=72.6% | lr=0.001000
2025-11-24 07:28:05,482 [coscl.py] => Epoch 22/100 | Train: loss=1.274, acc=62.4% | Val: loss=0.800, acc=72.0% | lr=0.001000
2025-11-24 07:28:07,202 [coscl.py] => Epoch 23/100 | Train: loss=1.259, acc=63.2% | Val: loss=0.817, acc=70.7% | lr=0.001000
2025-11-24 07:28:09,201 [coscl.py] => Epoch 24/100 | Train: loss=1.283, acc=62.4% | Val: loss=0.793, acc=71.9% | lr=0.001000
2025-11-24 07:28:11,121 [coscl.py] => Epoch 25/100 | Train: loss=1.263, acc=63.2% | Val: loss=0.795, acc=71.1% | lr=0.001000
2025-11-24 07:28:12,812 [coscl.py] => Epoch 26/100 | Train: loss=1.265, acc=62.8% | Val: loss=0.817, acc=70.6% | lr=0.001000
2025-11-24 07:28:14,607 [coscl.py] => Epoch 27/100 | Train: loss=1.240, acc=64.0% | Val: loss=0.779, acc=72.2% | lr=0.000333
2025-11-24 07:28:16,490 [coscl.py] => Epoch 28/100 | Train: loss=1.220, acc=63.0% | Val: loss=0.775, acc=72.4% | lr=0.000333
2025-11-24 07:28:18,223 [coscl.py] => Epoch 29/100 | Train: loss=1.203, acc=64.2% | Val: loss=0.779, acc=71.9% | lr=0.000333
2025-11-24 07:28:19,938 [coscl.py] => Epoch 30/100 | Train: loss=1.199, acc=64.1% | Val: loss=0.770, acc=73.2% | lr=0.000333
2025-11-24 07:28:21,755 [coscl.py] => Epoch 31/100 | Train: loss=1.198, acc=63.3% | Val: loss=0.778, acc=72.1% | lr=0.000333
2025-11-24 07:28:23,696 [coscl.py] => Epoch 32/100 | Train: loss=1.196, acc=64.1% | Val: loss=0.784, acc=71.8% | lr=0.000333
2025-11-24 07:28:25,598 [coscl.py] => Epoch 33/100 | Train: loss=1.184, acc=63.6% | Val: loss=0.768, acc=72.3% | lr=0.000333
2025-11-24 07:28:27,671 [coscl.py] => Epoch 34/100 | Train: loss=1.188, acc=63.7% | Val: loss=0.765, acc=73.1% | lr=0.000333
2025-11-24 07:28:29,421 [coscl.py] => Epoch 35/100 | Train: loss=1.172, acc=64.2% | Val: loss=0.776, acc=72.1% | lr=0.000333
2025-11-24 07:28:31,233 [coscl.py] => Epoch 36/100 | Train: loss=1.185, acc=64.3% | Val: loss=0.784, acc=71.6% | lr=0.000333
2025-11-24 07:28:33,433 [coscl.py] => Epoch 37/100 | Train: loss=1.173, acc=65.2% | Val: loss=0.760, acc=72.8% | lr=0.000333
2025-11-24 07:28:35,192 [coscl.py] => Epoch 38/100 | Train: loss=1.180, acc=64.1% | Val: loss=0.766, acc=72.7% | lr=0.000333
2025-11-24 07:28:36,901 [coscl.py] => Epoch 39/100 | Train: loss=1.191, acc=63.4% | Val: loss=0.772, acc=72.6% | lr=0.000333
2025-11-24 07:28:38,705 [coscl.py] => Epoch 40/100 | Train: loss=1.186, acc=64.8% | Val: loss=0.765, acc=73.0% | lr=0.000333
2025-11-24 07:28:40,533 [coscl.py] => Epoch 41/100 | Train: loss=1.182, acc=63.7% | Val: loss=0.764, acc=72.7% | lr=0.000333
2025-11-24 07:28:42,297 [coscl.py] => Epoch 42/100 | Train: loss=1.177, acc=64.3% | Val: loss=0.772, acc=72.5% | lr=0.000333
2025-11-24 07:28:44,204 [coscl.py] => Epoch 43/100 | Train: loss=1.170, acc=64.7% | Val: loss=0.765, acc=72.4% | lr=0.000111
2025-11-24 07:28:45,927 [coscl.py] => Epoch 44/100 | Train: loss=1.170, acc=64.3% | Val: loss=0.766, acc=72.9% | lr=0.000111
2025-11-24 07:28:47,759 [coscl.py] => Epoch 45/100 | Train: loss=1.162, acc=64.6% | Val: loss=0.760, acc=72.8% | lr=0.000111
2025-11-24 07:28:49,485 [coscl.py] => Epoch 46/100 | Train: loss=1.155, acc=64.6% | Val: loss=0.759, acc=73.4% | lr=0.000111
2025-11-24 07:28:51,253 [coscl.py] => Epoch 47/100 | Train: loss=1.148, acc=64.8% | Val: loss=0.756, acc=73.0% | lr=0.000111
2025-11-24 07:28:53,156 [coscl.py] => Epoch 48/100 | Train: loss=1.159, acc=64.6% | Val: loss=0.759, acc=73.2% | lr=0.000111
2025-11-24 07:28:54,925 [coscl.py] => Epoch 49/100 | Train: loss=1.164, acc=64.2% | Val: loss=0.754, acc=72.9% | lr=0.000111
2025-11-24 07:28:56,709 [coscl.py] => Epoch 50/100 | Train: loss=1.166, acc=64.5% | Val: loss=0.759, acc=73.1% | lr=0.000111
2025-11-24 07:28:58,451 [coscl.py] => Epoch 51/100 | Train: loss=1.164, acc=64.5% | Val: loss=0.756, acc=73.2% | lr=0.000111
2025-11-24 07:29:00,844 [coscl.py] => Epoch 52/100 | Train: loss=1.153, acc=65.3% | Val: loss=0.763, acc=72.5% | lr=0.000111
2025-11-24 07:29:02,685 [coscl.py] => Epoch 53/100 | Train: loss=1.161, acc=63.8% | Val: loss=0.766, acc=72.7% | lr=0.000111
2025-11-24 07:29:04,484 [coscl.py] => Epoch 54/100 | Train: loss=1.139, acc=65.0% | Val: loss=0.752, acc=73.4% | lr=0.000111
2025-11-24 07:29:06,352 [coscl.py] => Epoch 55/100 | Train: loss=1.162, acc=64.1% | Val: loss=0.757, acc=73.0% | lr=0.000111
2025-11-24 07:29:08,190 [coscl.py] => Epoch 56/100 | Train: loss=1.149, acc=65.0% | Val: loss=0.762, acc=73.0% | lr=0.000111
2025-11-24 07:29:10,056 [coscl.py] => Epoch 57/100 | Train: loss=1.162, acc=64.7% | Val: loss=0.759, acc=73.1% | lr=0.000111
2025-11-24 07:29:12,025 [coscl.py] => Epoch 58/100 | Train: loss=1.147, acc=64.8% | Val: loss=0.755, acc=73.1% | lr=0.000111
2025-11-24 07:29:13,789 [coscl.py] => Epoch 59/100 | Train: loss=1.133, acc=65.6% | Val: loss=0.760, acc=73.0% | lr=0.000111
2025-11-24 07:29:15,527 [coscl.py] => Epoch 60/100 | Train: loss=1.166, acc=64.5% | Val: loss=0.758, acc=73.2% | lr=0.000037
2025-11-24 07:29:17,231 [coscl.py] => Epoch 61/100 | Train: loss=1.150, acc=64.9% | Val: loss=0.755, acc=73.2% | lr=0.000037
2025-11-24 07:29:19,004 [coscl.py] => Epoch 62/100 | Train: loss=1.143, acc=64.9% | Val: loss=0.756, acc=73.1% | lr=0.000037
2025-11-24 07:29:20,872 [coscl.py] => Epoch 63/100 | Train: loss=1.148, acc=64.8% | Val: loss=0.755, acc=73.1% | lr=0.000037
2025-11-24 07:29:22,745 [coscl.py] => Epoch 64/100 | Train: loss=1.156, acc=64.5% | Val: loss=0.756, acc=73.1% | lr=0.000037
2025-11-24 07:29:24,623 [coscl.py] => Epoch 65/100 | Train: loss=1.153, acc=64.9% | Val: loss=0.756, acc=73.3% | lr=0.000012
2025-11-24 07:29:26,395 [coscl.py] => Epoch 66/100 | Train: loss=1.141, acc=64.7% | Val: loss=0.755, acc=73.2% | lr=0.000012
2025-11-24 07:29:28,130 [coscl.py] => Epoch 67/100 | Train: loss=1.152, acc=64.4% | Val: loss=0.755, acc=73.2% | lr=0.000012
2025-11-24 07:29:29,976 [coscl.py] => Epoch 68/100 | Train: loss=1.145, acc=65.7% | Val: loss=0.755, acc=73.2% | lr=0.000012
2025-11-24 07:29:31,759 [coscl.py] => Epoch 69/100 | Train: loss=1.140, acc=65.3% | Val: loss=0.754, acc=73.2% | lr=0.000012
2025-11-24 07:29:33,505 [coscl.py] => Epoch 70/100 | Train: loss=1.144, acc=65.1% | Val: loss=0.754, acc=73.2% | lr=0.000004
2025-11-24 07:29:35,489 [coscl.py] => Epoch 71/100 | Train: loss=1.145, acc=65.0% | Val: loss=0.755, acc=73.3% | lr=0.000004
2025-11-24 07:29:37,213 [coscl.py] => Epoch 72/100 | Train: loss=1.155, acc=63.9% | Val: loss=0.755, acc=73.3% | lr=0.000004
2025-11-24 07:29:39,350 [coscl.py] => Epoch 73/100 | Train: loss=1.153, acc=64.5% | Val: loss=0.755, acc=73.3% | lr=0.000004
2025-11-24 07:29:41,257 [coscl.py] => Epoch 74/100 | Train: loss=1.155, acc=64.6% | Val: loss=0.755, acc=73.3% | lr=0.000004
2025-11-24 07:29:43,134 [coscl.py] => Epoch 75/100 | Train: loss=1.144, acc=65.2% | Val: loss=0.755, acc=73.2% | lr=0.000001
2025-11-24 07:29:44,837 [coscl.py] => Epoch 76/100 | Train: loss=1.145, acc=64.1% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:29:46,603 [coscl.py] => Epoch 77/100 | Train: loss=1.155, acc=63.7% | Val: loss=0.756, acc=73.3% | lr=0.000001
2025-11-24 07:29:48,449 [coscl.py] => Epoch 78/100 | Train: loss=1.144, acc=64.8% | Val: loss=0.755, acc=73.2% | lr=0.000001
2025-11-24 07:29:50,158 [coscl.py] => Epoch 79/100 | Train: loss=1.147, acc=64.9% | Val: loss=0.755, acc=73.2% | lr=0.000001
2025-11-24 07:29:50,159 [coscl.py] => Learning rate reached minimum
2025-11-24 07:29:51,971 [coscl.py] => Epoch 80/100 | Train: loss=1.127, acc=65.5% | Val: loss=0.755, acc=73.2% | lr=0.000001
2025-11-24 07:29:51,971 [coscl.py] => Learning rate reached minimum
2025-11-24 07:29:54,006 [coscl.py] => Epoch 81/100 | Train: loss=1.141, acc=64.8% | Val: loss=0.755, acc=73.2% | lr=0.000001
2025-11-24 07:29:54,007 [coscl.py] => Learning rate reached minimum
2025-11-24 07:29:55,770 [coscl.py] => Epoch 82/100 | Train: loss=1.146, acc=64.2% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:29:55,770 [coscl.py] => Learning rate reached minimum
2025-11-24 07:29:57,576 [coscl.py] => Epoch 83/100 | Train: loss=1.136, acc=65.5% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:29:57,577 [coscl.py] => Learning rate reached minimum
2025-11-24 07:29:59,509 [coscl.py] => Epoch 84/100 | Train: loss=1.129, acc=65.1% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:29:59,510 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:01,401 [coscl.py] => Epoch 85/100 | Train: loss=1.146, acc=65.6% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:01,402 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:03,400 [coscl.py] => Epoch 86/100 | Train: loss=1.145, acc=65.5% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:03,400 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:05,336 [coscl.py] => Epoch 87/100 | Train: loss=1.151, acc=64.7% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:05,336 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:07,247 [coscl.py] => Epoch 88/100 | Train: loss=1.144, acc=64.6% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:07,248 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:09,235 [coscl.py] => Epoch 89/100 | Train: loss=1.155, acc=64.4% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:09,235 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:11,656 [coscl.py] => Epoch 90/100 | Train: loss=1.130, acc=65.5% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:11,656 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:13,884 [coscl.py] => Epoch 91/100 | Train: loss=1.138, acc=64.8% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:13,884 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:15,853 [coscl.py] => Epoch 92/100 | Train: loss=1.131, acc=65.6% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:15,853 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:17,804 [coscl.py] => Epoch 93/100 | Train: loss=1.135, acc=65.7% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:17,804 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:19,496 [coscl.py] => Epoch 94/100 | Train: loss=1.147, acc=64.9% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:19,496 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:21,220 [coscl.py] => Epoch 95/100 | Train: loss=1.147, acc=64.7% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:21,220 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:22,960 [coscl.py] => Epoch 96/100 | Train: loss=1.135, acc=65.8% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:22,961 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:24,751 [coscl.py] => Epoch 97/100 | Train: loss=1.125, acc=65.1% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:24,751 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:26,577 [coscl.py] => Epoch 98/100 | Train: loss=1.133, acc=64.9% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:26,578 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:28,311 [coscl.py] => Epoch 99/100 | Train: loss=1.127, acc=65.6% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:28,312 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:30,086 [coscl.py] => Epoch 100/100 | Train: loss=1.150, acc=65.0% | Val: loss=0.755, acc=73.3% | lr=0.000001
2025-11-24 07:30:30,087 [coscl.py] => Learning rate reached minimum
2025-11-24 07:30:32,452 [trainer.py] => No NME accuracy.
2025-11-24 07:30:32,453 [trainer.py] => CNN: {'total': np.float64(34.78), '00-09': np.float64(56.1), '10-19': np.float64(40.7), '20-29': np.float64(47.9), '30-39': np.float64(16.7), '40-49': np.float64(24.4), '50-59': np.float64(22.9), 'old': np.float64(37.16), 'new': np.float64(22.9)}
2025-11-24 07:30:32,453 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95), np.float64(38.3), np.float64(34.78)]
2025-11-24 07:30:32,453 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92), np.float64(75.02), np.float64(71.68)]

2025-11-24 07:30:32,453 [trainer.py] => Average Accuracy (CNN): 49.73333333333333 

2025-11-24 07:30:32,453 [trainer.py] => All params: 773260
2025-11-24 07:30:32,454 [trainer.py] => Trainable params: 773260
2025-11-24 07:30:34,316 [coscl.py] => Epoch 1/100 | Train: loss=2.223, acc=28.6% | Val: loss=1.428, acc=54.7% | lr=0.001000
2025-11-24 07:30:36,109 [coscl.py] => Epoch 2/100 | Train: loss=1.875, acc=46.4% | Val: loss=1.249, acc=61.2% | lr=0.001000
2025-11-24 07:30:37,787 [coscl.py] => Epoch 3/100 | Train: loss=1.757, acc=49.8% | Val: loss=1.177, acc=63.4% | lr=0.001000
2025-11-24 07:30:39,615 [coscl.py] => Epoch 4/100 | Train: loss=1.710, acc=51.8% | Val: loss=1.147, acc=63.4% | lr=0.001000
2025-11-24 07:30:41,337 [coscl.py] => Epoch 5/100 | Train: loss=1.668, acc=53.6% | Val: loss=1.118, acc=63.3% | lr=0.001000
2025-11-24 07:30:43,021 [coscl.py] => Epoch 6/100 | Train: loss=1.650, acc=53.3% | Val: loss=1.117, acc=64.6% | lr=0.001000
2025-11-24 07:30:44,857 [coscl.py] => Epoch 7/100 | Train: loss=1.622, acc=54.1% | Val: loss=1.083, acc=65.4% | lr=0.001000
2025-11-24 07:30:46,687 [coscl.py] => Epoch 8/100 | Train: loss=1.585, acc=55.9% | Val: loss=1.047, acc=67.2% | lr=0.001000
2025-11-24 07:30:48,383 [coscl.py] => Epoch 9/100 | Train: loss=1.588, acc=56.2% | Val: loss=1.036, acc=66.9% | lr=0.001000
2025-11-24 07:30:50,254 [coscl.py] => Epoch 10/100 | Train: loss=1.581, acc=56.1% | Val: loss=1.060, acc=65.9% | lr=0.001000
2025-11-24 07:30:52,264 [coscl.py] => Epoch 11/100 | Train: loss=1.558, acc=56.7% | Val: loss=1.040, acc=66.9% | lr=0.001000
2025-11-24 07:30:53,977 [coscl.py] => Epoch 12/100 | Train: loss=1.548, acc=56.6% | Val: loss=1.040, acc=67.2% | lr=0.001000
2025-11-24 07:30:55,748 [coscl.py] => Epoch 13/100 | Train: loss=1.546, acc=56.7% | Val: loss=1.032, acc=65.8% | lr=0.001000
2025-11-24 07:30:57,470 [coscl.py] => Epoch 14/100 | Train: loss=1.545, acc=57.0% | Val: loss=1.044, acc=66.0% | lr=0.001000
2025-11-24 07:30:59,156 [coscl.py] => Epoch 15/100 | Train: loss=1.540, acc=56.9% | Val: loss=0.995, acc=68.5% | lr=0.001000
2025-11-24 07:31:00,928 [coscl.py] => Epoch 16/100 | Train: loss=1.537, acc=57.1% | Val: loss=1.012, acc=67.2% | lr=0.001000
2025-11-24 07:31:02,644 [coscl.py] => Epoch 17/100 | Train: loss=1.529, acc=57.1% | Val: loss=0.986, acc=68.6% | lr=0.001000
2025-11-24 07:31:04,301 [coscl.py] => Epoch 18/100 | Train: loss=1.522, acc=56.5% | Val: loss=0.995, acc=67.9% | lr=0.001000
2025-11-24 07:31:06,108 [coscl.py] => Epoch 19/100 | Train: loss=1.486, acc=58.3% | Val: loss=1.000, acc=67.4% | lr=0.001000
2025-11-24 07:31:08,076 [coscl.py] => Epoch 20/100 | Train: loss=1.504, acc=57.2% | Val: loss=0.999, acc=67.2% | lr=0.001000
2025-11-24 07:31:09,824 [coscl.py] => Epoch 21/100 | Train: loss=1.508, acc=57.4% | Val: loss=0.989, acc=68.3% | lr=0.001000
2025-11-24 07:31:11,613 [coscl.py] => Epoch 22/100 | Train: loss=1.505, acc=57.6% | Val: loss=0.978, acc=68.8% | lr=0.001000
2025-11-24 07:31:13,307 [coscl.py] => Epoch 23/100 | Train: loss=1.506, acc=58.0% | Val: loss=0.994, acc=67.5% | lr=0.001000
2025-11-24 07:31:15,148 [coscl.py] => Epoch 24/100 | Train: loss=1.509, acc=57.7% | Val: loss=1.013, acc=66.5% | lr=0.001000
2025-11-24 07:31:16,852 [coscl.py] => Epoch 25/100 | Train: loss=1.541, acc=56.8% | Val: loss=0.998, acc=67.6% | lr=0.001000
2025-11-24 07:31:18,611 [coscl.py] => Epoch 26/100 | Train: loss=1.496, acc=58.1% | Val: loss=1.055, acc=64.6% | lr=0.001000
2025-11-24 07:31:20,468 [coscl.py] => Epoch 27/100 | Train: loss=1.515, acc=57.3% | Val: loss=0.988, acc=67.8% | lr=0.001000
2025-11-24 07:31:22,206 [coscl.py] => Epoch 28/100 | Train: loss=1.490, acc=58.5% | Val: loss=0.966, acc=68.8% | lr=0.000333
2025-11-24 07:31:23,931 [coscl.py] => Epoch 29/100 | Train: loss=1.442, acc=59.0% | Val: loss=0.979, acc=68.1% | lr=0.000333
2025-11-24 07:31:25,909 [coscl.py] => Epoch 30/100 | Train: loss=1.441, acc=58.3% | Val: loss=0.959, acc=68.7% | lr=0.000333
2025-11-24 07:31:27,925 [coscl.py] => Epoch 31/100 | Train: loss=1.425, acc=59.0% | Val: loss=0.950, acc=69.4% | lr=0.000333
2025-11-24 07:31:29,719 [coscl.py] => Epoch 32/100 | Train: loss=1.411, acc=59.4% | Val: loss=0.958, acc=68.9% | lr=0.000333
2025-11-24 07:31:31,750 [coscl.py] => Epoch 33/100 | Train: loss=1.413, acc=59.5% | Val: loss=0.953, acc=69.2% | lr=0.000333
2025-11-24 07:31:33,598 [coscl.py] => Epoch 34/100 | Train: loss=1.408, acc=59.6% | Val: loss=0.957, acc=68.8% | lr=0.000333
2025-11-24 07:31:35,311 [coscl.py] => Epoch 35/100 | Train: loss=1.405, acc=59.6% | Val: loss=0.966, acc=68.2% | lr=0.000333
2025-11-24 07:31:37,001 [coscl.py] => Epoch 36/100 | Train: loss=1.407, acc=58.6% | Val: loss=0.955, acc=69.0% | lr=0.000333
2025-11-24 07:31:38,740 [coscl.py] => Epoch 37/100 | Train: loss=1.407, acc=59.5% | Val: loss=0.947, acc=69.4% | lr=0.000111
2025-11-24 07:31:40,691 [coscl.py] => Epoch 38/100 | Train: loss=1.412, acc=59.0% | Val: loss=0.946, acc=69.4% | lr=0.000111
2025-11-24 07:31:42,429 [coscl.py] => Epoch 39/100 | Train: loss=1.401, acc=59.9% | Val: loss=0.947, acc=69.2% | lr=0.000111
2025-11-24 07:31:44,384 [coscl.py] => Epoch 40/100 | Train: loss=1.377, acc=60.2% | Val: loss=0.941, acc=69.6% | lr=0.000111
2025-11-24 07:31:46,127 [coscl.py] => Epoch 41/100 | Train: loss=1.384, acc=59.6% | Val: loss=0.948, acc=68.9% | lr=0.000111
2025-11-24 07:31:47,948 [coscl.py] => Epoch 42/100 | Train: loss=1.378, acc=59.3% | Val: loss=0.938, acc=70.0% | lr=0.000111
2025-11-24 07:31:49,725 [coscl.py] => Epoch 43/100 | Train: loss=1.382, acc=59.0% | Val: loss=0.941, acc=69.6% | lr=0.000111
2025-11-24 07:31:51,397 [coscl.py] => Epoch 44/100 | Train: loss=1.377, acc=59.9% | Val: loss=0.942, acc=69.8% | lr=0.000111
2025-11-24 07:31:53,143 [coscl.py] => Epoch 45/100 | Train: loss=1.376, acc=60.6% | Val: loss=0.947, acc=69.4% | lr=0.000111
2025-11-24 07:31:55,055 [coscl.py] => Epoch 46/100 | Train: loss=1.387, acc=60.0% | Val: loss=0.938, acc=69.8% | lr=0.000111
2025-11-24 07:31:56,756 [coscl.py] => Epoch 47/100 | Train: loss=1.390, acc=59.3% | Val: loss=0.940, acc=70.0% | lr=0.000111
2025-11-24 07:31:58,432 [coscl.py] => Epoch 48/100 | Train: loss=1.374, acc=60.5% | Val: loss=0.943, acc=69.4% | lr=0.000111
2025-11-24 07:32:00,234 [coscl.py] => Epoch 49/100 | Train: loss=1.372, acc=60.0% | Val: loss=0.936, acc=69.8% | lr=0.000111
2025-11-24 07:32:02,011 [coscl.py] => Epoch 50/100 | Train: loss=1.390, acc=59.2% | Val: loss=0.942, acc=69.6% | lr=0.000111
2025-11-24 07:32:03,785 [coscl.py] => Epoch 51/100 | Train: loss=1.364, acc=61.6% | Val: loss=0.943, acc=69.1% | lr=0.000111
2025-11-24 07:32:05,516 [coscl.py] => Epoch 52/100 | Train: loss=1.392, acc=58.9% | Val: loss=0.941, acc=69.3% | lr=0.000111
2025-11-24 07:32:07,506 [coscl.py] => Epoch 53/100 | Train: loss=1.391, acc=59.5% | Val: loss=0.943, acc=69.8% | lr=0.000111
2025-11-24 07:32:09,317 [coscl.py] => Epoch 54/100 | Train: loss=1.363, acc=60.8% | Val: loss=0.937, acc=69.9% | lr=0.000111
2025-11-24 07:32:11,475 [coscl.py] => Epoch 55/100 | Train: loss=1.377, acc=60.5% | Val: loss=0.939, acc=69.7% | lr=0.000037
2025-11-24 07:32:13,339 [coscl.py] => Epoch 56/100 | Train: loss=1.370, acc=60.2% | Val: loss=0.939, acc=69.9% | lr=0.000037
2025-11-24 07:32:15,133 [coscl.py] => Epoch 57/100 | Train: loss=1.374, acc=59.8% | Val: loss=0.938, acc=70.0% | lr=0.000037
2025-11-24 07:32:16,892 [coscl.py] => Epoch 58/100 | Train: loss=1.379, acc=58.9% | Val: loss=0.943, acc=69.8% | lr=0.000037
2025-11-24 07:32:18,682 [coscl.py] => Epoch 59/100 | Train: loss=1.374, acc=59.5% | Val: loss=0.936, acc=70.1% | lr=0.000037
2025-11-24 07:32:20,565 [coscl.py] => Epoch 60/100 | Train: loss=1.374, acc=59.1% | Val: loss=0.939, acc=69.9% | lr=0.000012
2025-11-24 07:32:22,330 [coscl.py] => Epoch 61/100 | Train: loss=1.378, acc=59.7% | Val: loss=0.938, acc=69.9% | lr=0.000012
2025-11-24 07:32:24,232 [coscl.py] => Epoch 62/100 | Train: loss=1.374, acc=60.0% | Val: loss=0.939, acc=70.0% | lr=0.000012
2025-11-24 07:32:25,956 [coscl.py] => Epoch 63/100 | Train: loss=1.366, acc=60.1% | Val: loss=0.939, acc=69.8% | lr=0.000012
2025-11-24 07:32:27,619 [coscl.py] => Epoch 64/100 | Train: loss=1.366, acc=60.7% | Val: loss=0.939, acc=69.6% | lr=0.000012
2025-11-24 07:32:29,506 [coscl.py] => Epoch 65/100 | Train: loss=1.371, acc=59.8% | Val: loss=0.938, acc=69.8% | lr=0.000004
2025-11-24 07:32:31,243 [coscl.py] => Epoch 66/100 | Train: loss=1.356, acc=60.1% | Val: loss=0.937, acc=69.9% | lr=0.000004
2025-11-24 07:32:32,937 [coscl.py] => Epoch 67/100 | Train: loss=1.383, acc=59.0% | Val: loss=0.938, acc=69.8% | lr=0.000004
2025-11-24 07:32:34,746 [coscl.py] => Epoch 68/100 | Train: loss=1.364, acc=60.2% | Val: loss=0.939, acc=69.8% | lr=0.000004
2025-11-24 07:32:36,624 [coscl.py] => Epoch 69/100 | Train: loss=1.353, acc=60.8% | Val: loss=0.938, acc=69.8% | lr=0.000004
2025-11-24 07:32:38,346 [coscl.py] => Epoch 70/100 | Train: loss=1.347, acc=61.3% | Val: loss=0.938, acc=69.7% | lr=0.000001
2025-11-24 07:32:40,007 [coscl.py] => Epoch 71/100 | Train: loss=1.378, acc=59.3% | Val: loss=0.938, acc=69.7% | lr=0.000001
2025-11-24 07:32:41,911 [coscl.py] => Epoch 72/100 | Train: loss=1.358, acc=60.1% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:43,621 [coscl.py] => Epoch 73/100 | Train: loss=1.361, acc=60.2% | Val: loss=0.938, acc=69.7% | lr=0.000001
2025-11-24 07:32:45,789 [coscl.py] => Epoch 74/100 | Train: loss=1.367, acc=59.9% | Val: loss=0.938, acc=69.7% | lr=0.000001
2025-11-24 07:32:45,790 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:47,563 [coscl.py] => Epoch 75/100 | Train: loss=1.363, acc=59.8% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:47,563 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:49,233 [coscl.py] => Epoch 76/100 | Train: loss=1.376, acc=59.3% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:49,234 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:51,071 [coscl.py] => Epoch 77/100 | Train: loss=1.370, acc=59.9% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:51,072 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:52,856 [coscl.py] => Epoch 78/100 | Train: loss=1.366, acc=59.9% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:52,857 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:54,548 [coscl.py] => Epoch 79/100 | Train: loss=1.371, acc=59.8% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:54,548 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:56,413 [coscl.py] => Epoch 80/100 | Train: loss=1.355, acc=60.9% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:56,413 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:58,116 [coscl.py] => Epoch 81/100 | Train: loss=1.352, acc=60.7% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:32:58,116 [coscl.py] => Learning rate reached minimum
2025-11-24 07:32:59,919 [coscl.py] => Epoch 82/100 | Train: loss=1.365, acc=60.7% | Val: loss=0.938, acc=69.9% | lr=0.000001
2025-11-24 07:32:59,919 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:01,666 [coscl.py] => Epoch 83/100 | Train: loss=1.381, acc=59.2% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:01,667 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:03,387 [coscl.py] => Epoch 84/100 | Train: loss=1.372, acc=60.5% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:03,387 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:05,155 [coscl.py] => Epoch 85/100 | Train: loss=1.358, acc=59.9% | Val: loss=0.939, acc=69.8% | lr=0.000001
2025-11-24 07:33:05,155 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:06,903 [coscl.py] => Epoch 86/100 | Train: loss=1.368, acc=60.3% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:06,903 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:08,647 [coscl.py] => Epoch 87/100 | Train: loss=1.368, acc=60.2% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:08,647 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:13,395 [coscl.py] => Epoch 88/100 | Train: loss=1.372, acc=60.3% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:13,401 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:15,889 [coscl.py] => Epoch 89/100 | Train: loss=1.356, acc=60.3% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:15,889 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:18,144 [coscl.py] => Epoch 90/100 | Train: loss=1.371, acc=59.7% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:18,145 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:20,379 [coscl.py] => Epoch 91/100 | Train: loss=1.365, acc=60.6% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:20,380 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:22,183 [coscl.py] => Epoch 92/100 | Train: loss=1.380, acc=60.6% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:22,183 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:23,874 [coscl.py] => Epoch 93/100 | Train: loss=1.365, acc=59.9% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:23,874 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:26,138 [coscl.py] => Epoch 94/100 | Train: loss=1.356, acc=60.4% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:26,139 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:28,616 [coscl.py] => Epoch 95/100 | Train: loss=1.355, acc=60.1% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:28,617 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:30,352 [coscl.py] => Epoch 96/100 | Train: loss=1.361, acc=60.5% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:30,352 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:32,171 [coscl.py] => Epoch 97/100 | Train: loss=1.365, acc=60.6% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:32,172 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:34,052 [coscl.py] => Epoch 98/100 | Train: loss=1.361, acc=60.7% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:34,053 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:35,763 [coscl.py] => Epoch 99/100 | Train: loss=1.367, acc=59.9% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:35,764 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:37,446 [coscl.py] => Epoch 100/100 | Train: loss=1.362, acc=59.8% | Val: loss=0.938, acc=69.8% | lr=0.000001
2025-11-24 07:33:37,447 [coscl.py] => Learning rate reached minimum
2025-11-24 07:33:40,303 [trainer.py] => No NME accuracy.
2025-11-24 07:33:40,303 [trainer.py] => CNN: {'total': np.float64(31.46), '00-09': np.float64(54.1), '10-19': np.float64(38.1), '20-29': np.float64(45.5), '30-39': np.float64(13.5), '40-49': np.float64(23.6), '50-59': np.float64(21.9), '60-69': np.float64(23.5), 'old': np.float64(32.78), 'new': np.float64(23.5)}
2025-11-24 07:33:40,303 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95), np.float64(38.3), np.float64(34.78), np.float64(31.46)]
2025-11-24 07:33:40,303 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92), np.float64(75.02), np.float64(71.68), np.float64(68.34)]

2025-11-24 07:33:40,303 [trainer.py] => Average Accuracy (CNN): 47.122857142857136 

2025-11-24 07:33:40,304 [trainer.py] => All params: 773260
2025-11-24 07:33:40,304 [trainer.py] => Trainable params: 773260
2025-11-24 07:33:42,112 [coscl.py] => Epoch 1/100 | Train: loss=2.100, acc=35.5% | Val: loss=1.164, acc=62.6% | lr=0.001000
2025-11-24 07:33:43,975 [coscl.py] => Epoch 2/100 | Train: loss=1.682, acc=53.1% | Val: loss=1.008, acc=68.4% | lr=0.001000
2025-11-24 07:33:45,670 [coscl.py] => Epoch 3/100 | Train: loss=1.572, acc=57.0% | Val: loss=0.962, acc=69.7% | lr=0.001000
2025-11-24 07:33:47,587 [coscl.py] => Epoch 4/100 | Train: loss=1.527, acc=58.2% | Val: loss=0.967, acc=69.3% | lr=0.001000
2025-11-24 07:33:49,401 [coscl.py] => Epoch 5/100 | Train: loss=1.475, acc=59.8% | Val: loss=0.893, acc=71.7% | lr=0.001000
2025-11-24 07:33:51,098 [coscl.py] => Epoch 6/100 | Train: loss=1.433, acc=61.1% | Val: loss=0.878, acc=71.9% | lr=0.001000
2025-11-24 07:33:52,893 [coscl.py] => Epoch 7/100 | Train: loss=1.425, acc=60.8% | Val: loss=0.883, acc=72.1% | lr=0.001000
2025-11-24 07:33:55,164 [coscl.py] => Epoch 8/100 | Train: loss=1.388, acc=62.0% | Val: loss=0.842, acc=72.5% | lr=0.001000
2025-11-24 07:33:56,891 [coscl.py] => Epoch 9/100 | Train: loss=1.397, acc=61.3% | Val: loss=0.854, acc=72.9% | lr=0.001000
2025-11-24 07:33:58,626 [coscl.py] => Epoch 10/100 | Train: loss=1.371, acc=62.6% | Val: loss=0.842, acc=72.5% | lr=0.001000
2025-11-24 07:34:00,805 [coscl.py] => Epoch 11/100 | Train: loss=1.362, acc=61.7% | Val: loss=0.845, acc=72.5% | lr=0.001000
2025-11-24 07:34:02,517 [coscl.py] => Epoch 12/100 | Train: loss=1.348, acc=63.0% | Val: loss=0.828, acc=73.2% | lr=0.001000
2025-11-24 07:34:04,229 [coscl.py] => Epoch 13/100 | Train: loss=1.338, acc=63.7% | Val: loss=0.827, acc=72.9% | lr=0.001000
2025-11-24 07:34:06,029 [coscl.py] => Epoch 14/100 | Train: loss=1.335, acc=64.2% | Val: loss=0.847, acc=72.0% | lr=0.001000
2025-11-24 07:34:07,745 [coscl.py] => Epoch 15/100 | Train: loss=1.330, acc=64.3% | Val: loss=0.814, acc=73.6% | lr=0.001000
2025-11-24 07:34:09,575 [coscl.py] => Epoch 16/100 | Train: loss=1.332, acc=63.6% | Val: loss=0.819, acc=74.2% | lr=0.001000
2025-11-24 07:34:11,971 [coscl.py] => Epoch 17/100 | Train: loss=1.342, acc=63.9% | Val: loss=0.834, acc=72.7% | lr=0.001000
2025-11-24 07:34:13,716 [coscl.py] => Epoch 18/100 | Train: loss=1.323, acc=63.2% | Val: loss=0.790, acc=74.3% | lr=0.001000
2025-11-24 07:34:15,584 [coscl.py] => Epoch 19/100 | Train: loss=1.326, acc=64.0% | Val: loss=0.806, acc=74.2% | lr=0.001000
2025-11-24 07:34:17,440 [coscl.py] => Epoch 20/100 | Train: loss=1.302, acc=64.6% | Val: loss=0.825, acc=73.5% | lr=0.001000
2025-11-24 07:34:19,199 [coscl.py] => Epoch 21/100 | Train: loss=1.335, acc=62.7% | Val: loss=0.799, acc=73.5% | lr=0.001000
2025-11-24 07:34:21,029 [coscl.py] => Epoch 22/100 | Train: loss=1.326, acc=64.4% | Val: loss=0.796, acc=73.6% | lr=0.001000
2025-11-24 07:34:23,036 [coscl.py] => Epoch 23/100 | Train: loss=1.295, acc=64.9% | Val: loss=0.817, acc=73.7% | lr=0.001000
2025-11-24 07:34:24,867 [coscl.py] => Epoch 24/100 | Train: loss=1.282, acc=64.2% | Val: loss=0.780, acc=74.8% | lr=0.000333
2025-11-24 07:34:26,635 [coscl.py] => Epoch 25/100 | Train: loss=1.251, acc=65.3% | Val: loss=0.778, acc=74.4% | lr=0.000333
2025-11-24 07:34:28,425 [coscl.py] => Epoch 26/100 | Train: loss=1.249, acc=64.5% | Val: loss=0.774, acc=74.5% | lr=0.000333
2025-11-24 07:34:30,514 [coscl.py] => Epoch 27/100 | Train: loss=1.225, acc=65.5% | Val: loss=0.777, acc=74.6% | lr=0.000333
2025-11-24 07:34:32,394 [coscl.py] => Epoch 28/100 | Train: loss=1.235, acc=64.3% | Val: loss=0.782, acc=74.4% | lr=0.000333
2025-11-24 07:34:34,117 [coscl.py] => Epoch 29/100 | Train: loss=1.235, acc=64.6% | Val: loss=0.772, acc=75.1% | lr=0.000333
2025-11-24 07:34:35,857 [coscl.py] => Epoch 30/100 | Train: loss=1.224, acc=65.2% | Val: loss=0.771, acc=75.0% | lr=0.000333
2025-11-24 07:34:37,659 [coscl.py] => Epoch 31/100 | Train: loss=1.220, acc=65.3% | Val: loss=0.775, acc=74.7% | lr=0.000333
2025-11-24 07:34:39,384 [coscl.py] => Epoch 32/100 | Train: loss=1.224, acc=65.1% | Val: loss=0.782, acc=74.4% | lr=0.000333
2025-11-24 07:34:41,263 [coscl.py] => Epoch 33/100 | Train: loss=1.232, acc=64.9% | Val: loss=0.772, acc=75.0% | lr=0.000333
2025-11-24 07:34:43,125 [coscl.py] => Epoch 34/100 | Train: loss=1.216, acc=65.5% | Val: loss=0.771, acc=74.6% | lr=0.000333
2025-11-24 07:34:44,844 [coscl.py] => Epoch 35/100 | Train: loss=1.231, acc=64.9% | Val: loss=0.765, acc=75.2% | lr=0.000333
2025-11-24 07:34:46,736 [coscl.py] => Epoch 36/100 | Train: loss=1.227, acc=65.3% | Val: loss=0.773, acc=75.1% | lr=0.000333
2025-11-24 07:34:48,478 [coscl.py] => Epoch 37/100 | Train: loss=1.232, acc=65.5% | Val: loss=0.770, acc=74.7% | lr=0.000333
2025-11-24 07:34:50,295 [coscl.py] => Epoch 38/100 | Train: loss=1.211, acc=66.1% | Val: loss=0.769, acc=75.1% | lr=0.000333
2025-11-24 07:34:52,288 [coscl.py] => Epoch 39/100 | Train: loss=1.202, acc=66.0% | Val: loss=0.772, acc=74.5% | lr=0.000333
2025-11-24 07:34:54,032 [coscl.py] => Epoch 40/100 | Train: loss=1.215, acc=65.7% | Val: loss=0.767, acc=75.4% | lr=0.000333
2025-11-24 07:34:55,841 [coscl.py] => Epoch 41/100 | Train: loss=1.206, acc=66.0% | Val: loss=0.760, acc=75.3% | lr=0.000111
2025-11-24 07:34:57,644 [coscl.py] => Epoch 42/100 | Train: loss=1.213, acc=65.4% | Val: loss=0.761, acc=75.1% | lr=0.000111
2025-11-24 07:34:59,347 [coscl.py] => Epoch 43/100 | Train: loss=1.192, acc=66.0% | Val: loss=0.760, acc=75.2% | lr=0.000111
2025-11-24 07:35:01,597 [coscl.py] => Epoch 44/100 | Train: loss=1.186, acc=66.1% | Val: loss=0.756, acc=75.4% | lr=0.000111
2025-11-24 07:35:03,416 [coscl.py] => Epoch 45/100 | Train: loss=1.188, acc=65.8% | Val: loss=0.759, acc=75.3% | lr=0.000111
2025-11-24 07:35:05,263 [coscl.py] => Epoch 46/100 | Train: loss=1.183, acc=66.0% | Val: loss=0.758, acc=74.9% | lr=0.000111
2025-11-24 07:35:07,272 [coscl.py] => Epoch 47/100 | Train: loss=1.213, acc=65.1% | Val: loss=0.760, acc=75.1% | lr=0.000111
2025-11-24 07:35:09,115 [coscl.py] => Epoch 48/100 | Train: loss=1.190, acc=65.9% | Val: loss=0.763, acc=75.4% | lr=0.000111
2025-11-24 07:35:16,224 [coscl.py] => Epoch 49/100 | Train: loss=1.193, acc=66.1% | Val: loss=0.762, acc=75.3% | lr=0.000111
2025-11-24 07:35:18,682 [coscl.py] => Epoch 50/100 | Train: loss=1.181, acc=65.9% | Val: loss=0.757, acc=75.3% | lr=0.000037
2025-11-24 07:35:20,404 [coscl.py] => Epoch 51/100 | Train: loss=1.171, acc=65.8% | Val: loss=0.757, acc=75.2% | lr=0.000037
2025-11-24 07:35:22,201 [coscl.py] => Epoch 52/100 | Train: loss=1.188, acc=66.3% | Val: loss=0.760, acc=75.3% | lr=0.000037
2025-11-24 07:35:24,072 [coscl.py] => Epoch 53/100 | Train: loss=1.186, acc=65.2% | Val: loss=0.758, acc=75.6% | lr=0.000037
2025-11-24 07:35:25,777 [coscl.py] => Epoch 54/100 | Train: loss=1.182, acc=65.8% | Val: loss=0.758, acc=75.4% | lr=0.000037
2025-11-24 07:35:27,586 [coscl.py] => Epoch 55/100 | Train: loss=1.187, acc=65.7% | Val: loss=0.757, acc=75.4% | lr=0.000012
2025-11-24 07:35:29,643 [coscl.py] => Epoch 56/100 | Train: loss=1.176, acc=66.3% | Val: loss=0.759, acc=75.4% | lr=0.000012
2025-11-24 07:35:31,336 [coscl.py] => Epoch 57/100 | Train: loss=1.184, acc=65.8% | Val: loss=0.758, acc=75.3% | lr=0.000012
2025-11-24 07:35:33,210 [coscl.py] => Epoch 58/100 | Train: loss=1.190, acc=65.4% | Val: loss=0.757, acc=75.2% | lr=0.000012
2025-11-24 07:35:35,091 [coscl.py] => Epoch 59/100 | Train: loss=1.172, acc=66.2% | Val: loss=0.758, acc=75.3% | lr=0.000012
2025-11-24 07:35:36,833 [coscl.py] => Epoch 60/100 | Train: loss=1.188, acc=65.8% | Val: loss=0.759, acc=75.2% | lr=0.000004
2025-11-24 07:35:38,603 [coscl.py] => Epoch 61/100 | Train: loss=1.156, acc=67.0% | Val: loss=0.758, acc=75.3% | lr=0.000004
2025-11-24 07:35:41,176 [coscl.py] => Epoch 62/100 | Train: loss=1.176, acc=65.9% | Val: loss=0.757, acc=75.3% | lr=0.000004
2025-11-24 07:35:42,965 [coscl.py] => Epoch 63/100 | Train: loss=1.182, acc=66.2% | Val: loss=0.757, acc=75.4% | lr=0.000004
2025-11-24 07:35:44,751 [coscl.py] => Epoch 64/100 | Train: loss=1.184, acc=66.6% | Val: loss=0.757, acc=75.4% | lr=0.000004
2025-11-24 07:35:46,614 [coscl.py] => Epoch 65/100 | Train: loss=1.180, acc=65.3% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:48,464 [coscl.py] => Epoch 66/100 | Train: loss=1.179, acc=65.0% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:50,152 [coscl.py] => Epoch 67/100 | Train: loss=1.173, acc=66.2% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:52,117 [coscl.py] => Epoch 68/100 | Train: loss=1.175, acc=66.5% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:54,052 [coscl.py] => Epoch 69/100 | Train: loss=1.188, acc=64.9% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:54,052 [coscl.py] => Learning rate reached minimum
2025-11-24 07:35:55,734 [coscl.py] => Epoch 70/100 | Train: loss=1.190, acc=65.4% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:55,735 [coscl.py] => Learning rate reached minimum
2025-11-24 07:35:57,540 [coscl.py] => Epoch 71/100 | Train: loss=1.186, acc=66.1% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:57,540 [coscl.py] => Learning rate reached minimum
2025-11-24 07:35:59,372 [coscl.py] => Epoch 72/100 | Train: loss=1.185, acc=66.1% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:35:59,373 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:01,078 [coscl.py] => Epoch 73/100 | Train: loss=1.186, acc=65.2% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:36:01,079 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:03,355 [coscl.py] => Epoch 74/100 | Train: loss=1.199, acc=65.9% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:36:03,356 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:05,157 [coscl.py] => Epoch 75/100 | Train: loss=1.182, acc=65.8% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:36:05,158 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:06,871 [coscl.py] => Epoch 76/100 | Train: loss=1.183, acc=66.4% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:36:06,872 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:08,770 [coscl.py] => Epoch 77/100 | Train: loss=1.174, acc=66.3% | Val: loss=0.758, acc=75.4% | lr=0.000001
2025-11-24 07:36:08,771 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:11,281 [coscl.py] => Epoch 78/100 | Train: loss=1.161, acc=66.9% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:11,282 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:13,468 [coscl.py] => Epoch 79/100 | Train: loss=1.178, acc=66.4% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:13,469 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:15,527 [coscl.py] => Epoch 80/100 | Train: loss=1.179, acc=66.0% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:15,528 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:17,309 [coscl.py] => Epoch 81/100 | Train: loss=1.168, acc=66.0% | Val: loss=0.757, acc=75.4% | lr=0.000001
2025-11-24 07:36:17,309 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:19,074 [coscl.py] => Epoch 82/100 | Train: loss=1.186, acc=65.8% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:19,075 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:21,329 [coscl.py] => Epoch 83/100 | Train: loss=1.166, acc=66.9% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:21,329 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:23,072 [coscl.py] => Epoch 84/100 | Train: loss=1.180, acc=65.9% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:23,072 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:24,835 [coscl.py] => Epoch 85/100 | Train: loss=1.179, acc=66.0% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:24,835 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:27,159 [coscl.py] => Epoch 86/100 | Train: loss=1.169, acc=66.3% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:27,160 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:28,899 [coscl.py] => Epoch 87/100 | Train: loss=1.184, acc=66.4% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:28,900 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:30,776 [coscl.py] => Epoch 88/100 | Train: loss=1.185, acc=65.9% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:30,776 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:32,573 [coscl.py] => Epoch 89/100 | Train: loss=1.173, acc=67.1% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:32,574 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:34,320 [coscl.py] => Epoch 90/100 | Train: loss=1.172, acc=66.4% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:34,320 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:36,332 [coscl.py] => Epoch 91/100 | Train: loss=1.171, acc=66.2% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:36,332 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:38,085 [coscl.py] => Epoch 92/100 | Train: loss=1.186, acc=66.0% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:38,085 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:39,802 [coscl.py] => Epoch 93/100 | Train: loss=1.172, acc=66.0% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:39,803 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:41,616 [coscl.py] => Epoch 94/100 | Train: loss=1.170, acc=66.7% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:41,616 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:43,401 [coscl.py] => Epoch 95/100 | Train: loss=1.180, acc=66.3% | Val: loss=0.758, acc=75.2% | lr=0.000001
2025-11-24 07:36:43,401 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:45,090 [coscl.py] => Epoch 96/100 | Train: loss=1.176, acc=66.0% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:45,090 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:46,875 [coscl.py] => Epoch 97/100 | Train: loss=1.173, acc=66.4% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:46,876 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:49,011 [coscl.py] => Epoch 98/100 | Train: loss=1.173, acc=65.9% | Val: loss=0.758, acc=75.3% | lr=0.000001
2025-11-24 07:36:49,011 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:50,697 [coscl.py] => Epoch 99/100 | Train: loss=1.180, acc=65.7% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:50,698 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:52,468 [coscl.py] => Epoch 100/100 | Train: loss=1.178, acc=66.3% | Val: loss=0.757, acc=75.3% | lr=0.000001
2025-11-24 07:36:52,469 [coscl.py] => Learning rate reached minimum
2025-11-24 07:36:55,859 [trainer.py] => No NME accuracy.
2025-11-24 07:36:55,859 [trainer.py] => CNN: {'total': np.float64(28.06), '00-09': np.float64(53.9), '10-19': np.float64(38.5), '20-29': np.float64(43.6), '30-39': np.float64(12.1), '40-49': np.float64(22.6), '50-59': np.float64(20.7), '60-69': np.float64(22.4), '70-79': np.float64(10.7), 'old': np.float64(30.54), 'new': np.float64(10.7)}
2025-11-24 07:36:55,860 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95), np.float64(38.3), np.float64(34.78), np.float64(31.46), np.float64(28.06)]
2025-11-24 07:36:55,860 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92), np.float64(75.02), np.float64(71.68), np.float64(68.34), np.float64(63.76)]

2025-11-24 07:36:55,860 [trainer.py] => Average Accuracy (CNN): 44.739999999999995 

2025-11-24 07:36:55,860 [trainer.py] => All params: 773260
2025-11-24 07:36:55,860 [trainer.py] => Trainable params: 773260
2025-11-24 07:36:58,147 [coscl.py] => Epoch 1/100 | Train: loss=2.080, acc=35.8% | Val: loss=1.257, acc=57.4% | lr=0.001000
2025-11-24 07:36:59,861 [coscl.py] => Epoch 2/100 | Train: loss=1.753, acc=50.0% | Val: loss=1.130, acc=63.6% | lr=0.001000
2025-11-24 07:37:01,660 [coscl.py] => Epoch 3/100 | Train: loss=1.650, acc=53.2% | Val: loss=1.083, acc=64.6% | lr=0.001000
2025-11-24 07:37:03,511 [coscl.py] => Epoch 4/100 | Train: loss=1.583, acc=54.8% | Val: loss=1.063, acc=65.3% | lr=0.001000
2025-11-24 07:37:05,269 [coscl.py] => Epoch 5/100 | Train: loss=1.538, acc=56.0% | Val: loss=1.023, acc=67.3% | lr=0.001000
2025-11-24 07:37:07,392 [coscl.py] => Epoch 6/100 | Train: loss=1.517, acc=56.9% | Val: loss=1.007, acc=67.3% | lr=0.001000
2025-11-24 07:37:09,246 [coscl.py] => Epoch 7/100 | Train: loss=1.498, acc=56.7% | Val: loss=1.005, acc=66.9% | lr=0.001000
2025-11-24 07:37:12,408 [coscl.py] => Epoch 8/100 | Train: loss=1.482, acc=57.5% | Val: loss=1.003, acc=66.9% | lr=0.001000
2025-11-24 07:37:14,601 [coscl.py] => Epoch 9/100 | Train: loss=1.493, acc=58.4% | Val: loss=1.003, acc=65.6% | lr=0.001000
2025-11-24 07:37:16,532 [coscl.py] => Epoch 10/100 | Train: loss=1.485, acc=57.5% | Val: loss=0.977, acc=68.3% | lr=0.001000
2025-11-24 07:37:18,325 [coscl.py] => Epoch 11/100 | Train: loss=1.450, acc=58.1% | Val: loss=0.980, acc=66.8% | lr=0.001000
2025-11-24 07:37:20,047 [coscl.py] => Epoch 12/100 | Train: loss=1.434, acc=58.4% | Val: loss=0.974, acc=67.3% | lr=0.001000
2025-11-24 07:37:22,067 [coscl.py] => Epoch 13/100 | Train: loss=1.437, acc=58.7% | Val: loss=0.994, acc=66.4% | lr=0.001000
2025-11-24 07:37:24,269 [coscl.py] => Epoch 14/100 | Train: loss=1.430, acc=59.2% | Val: loss=0.970, acc=67.2% | lr=0.001000
2025-11-24 07:37:25,979 [coscl.py] => Epoch 15/100 | Train: loss=1.421, acc=59.1% | Val: loss=0.964, acc=67.2% | lr=0.001000
2025-11-24 07:37:27,805 [coscl.py] => Epoch 16/100 | Train: loss=1.434, acc=58.3% | Val: loss=0.955, acc=67.6% | lr=0.001000
2025-11-24 07:37:30,051 [coscl.py] => Epoch 17/100 | Train: loss=1.443, acc=58.2% | Val: loss=0.964, acc=66.9% | lr=0.001000
2025-11-24 07:37:31,823 [coscl.py] => Epoch 18/100 | Train: loss=1.417, acc=59.4% | Val: loss=0.936, acc=68.4% | lr=0.001000
2025-11-24 07:37:33,857 [coscl.py] => Epoch 19/100 | Train: loss=1.409, acc=60.1% | Val: loss=0.947, acc=68.1% | lr=0.001000
2025-11-24 07:37:35,677 [coscl.py] => Epoch 20/100 | Train: loss=1.412, acc=60.0% | Val: loss=0.959, acc=67.5% | lr=0.001000
2025-11-24 07:37:37,563 [coscl.py] => Epoch 21/100 | Train: loss=1.414, acc=59.1% | Val: loss=0.951, acc=66.7% | lr=0.001000
2025-11-24 07:37:39,495 [coscl.py] => Epoch 22/100 | Train: loss=1.429, acc=58.9% | Val: loss=0.932, acc=68.8% | lr=0.001000
2025-11-24 07:37:41,248 [coscl.py] => Epoch 23/100 | Train: loss=1.398, acc=60.2% | Val: loss=0.936, acc=68.2% | lr=0.001000
2025-11-24 07:37:43,055 [coscl.py] => Epoch 24/100 | Train: loss=1.407, acc=60.0% | Val: loss=0.937, acc=68.1% | lr=0.001000
2025-11-24 07:37:44,897 [coscl.py] => Epoch 25/100 | Train: loss=1.405, acc=59.6% | Val: loss=0.928, acc=68.2% | lr=0.001000
2025-11-24 07:37:46,656 [coscl.py] => Epoch 26/100 | Train: loss=1.388, acc=60.2% | Val: loss=0.943, acc=67.9% | lr=0.001000
2025-11-24 07:37:48,440 [coscl.py] => Epoch 27/100 | Train: loss=1.397, acc=60.0% | Val: loss=0.935, acc=68.0% | lr=0.001000
2025-11-24 07:37:50,167 [coscl.py] => Epoch 28/100 | Train: loss=1.404, acc=60.5% | Val: loss=0.937, acc=68.3% | lr=0.001000
2025-11-24 07:37:51,927 [coscl.py] => Epoch 29/100 | Train: loss=1.398, acc=60.3% | Val: loss=0.924, acc=68.6% | lr=0.001000
2025-11-24 07:37:53,902 [coscl.py] => Epoch 30/100 | Train: loss=1.388, acc=60.8% | Val: loss=0.919, acc=68.7% | lr=0.001000
2025-11-24 07:37:55,633 [coscl.py] => Epoch 31/100 | Train: loss=1.389, acc=60.7% | Val: loss=0.911, acc=68.9% | lr=0.001000
2025-11-24 07:37:57,425 [coscl.py] => Epoch 32/100 | Train: loss=1.412, acc=60.0% | Val: loss=0.917, acc=69.1% | lr=0.001000
2025-11-24 07:37:59,231 [coscl.py] => Epoch 33/100 | Train: loss=1.407, acc=59.7% | Val: loss=0.928, acc=68.3% | lr=0.001000
2025-11-24 07:38:00,932 [coscl.py] => Epoch 34/100 | Train: loss=1.401, acc=60.1% | Val: loss=0.940, acc=67.8% | lr=0.001000
2025-11-24 07:38:03,111 [coscl.py] => Epoch 35/100 | Train: loss=1.390, acc=60.5% | Val: loss=0.924, acc=68.9% | lr=0.001000
2025-11-24 07:38:05,165 [coscl.py] => Epoch 36/100 | Train: loss=1.411, acc=60.1% | Val: loss=0.934, acc=69.2% | lr=0.001000
2025-11-24 07:38:06,966 [coscl.py] => Epoch 37/100 | Train: loss=1.364, acc=61.2% | Val: loss=0.917, acc=68.4% | lr=0.000333
2025-11-24 07:38:08,865 [coscl.py] => Epoch 38/100 | Train: loss=1.353, acc=60.8% | Val: loss=0.896, acc=69.5% | lr=0.000333
2025-11-24 07:38:10,866 [coscl.py] => Epoch 39/100 | Train: loss=1.331, acc=60.2% | Val: loss=0.913, acc=69.2% | lr=0.000333
2025-11-24 07:38:12,644 [coscl.py] => Epoch 40/100 | Train: loss=1.319, acc=61.2% | Val: loss=0.897, acc=69.7% | lr=0.000333
2025-11-24 07:38:14,404 [coscl.py] => Epoch 41/100 | Train: loss=1.303, acc=61.8% | Val: loss=0.903, acc=69.3% | lr=0.000333
2025-11-24 07:38:16,283 [coscl.py] => Epoch 42/100 | Train: loss=1.318, acc=60.8% | Val: loss=0.903, acc=69.4% | lr=0.000333
2025-11-24 07:38:18,023 [coscl.py] => Epoch 43/100 | Train: loss=1.299, acc=61.7% | Val: loss=0.891, acc=70.3% | lr=0.000333
2025-11-24 07:38:19,775 [coscl.py] => Epoch 44/100 | Train: loss=1.297, acc=61.0% | Val: loss=0.909, acc=68.8% | lr=0.000333
2025-11-24 07:38:21,559 [coscl.py] => Epoch 45/100 | Train: loss=1.317, acc=61.2% | Val: loss=0.895, acc=69.8% | lr=0.000333
2025-11-24 07:38:23,294 [coscl.py] => Epoch 46/100 | Train: loss=1.325, acc=60.1% | Val: loss=0.907, acc=69.4% | lr=0.000333
2025-11-24 07:38:24,996 [coscl.py] => Epoch 47/100 | Train: loss=1.314, acc=60.8% | Val: loss=0.891, acc=70.2% | lr=0.000333
2025-11-24 07:38:27,005 [coscl.py] => Epoch 48/100 | Train: loss=1.301, acc=61.9% | Val: loss=0.894, acc=69.6% | lr=0.000333
2025-11-24 07:38:28,729 [coscl.py] => Epoch 49/100 | Train: loss=1.306, acc=61.3% | Val: loss=0.889, acc=70.1% | lr=0.000333
2025-11-24 07:38:30,692 [coscl.py] => Epoch 50/100 | Train: loss=1.306, acc=61.7% | Val: loss=0.888, acc=70.0% | lr=0.000333
2025-11-24 07:38:32,554 [coscl.py] => Epoch 51/100 | Train: loss=1.294, acc=61.8% | Val: loss=0.899, acc=69.3% | lr=0.000333
2025-11-24 07:38:34,246 [coscl.py] => Epoch 52/100 | Train: loss=1.315, acc=61.1% | Val: loss=0.902, acc=69.4% | lr=0.000333
2025-11-24 07:38:36,227 [coscl.py] => Epoch 53/100 | Train: loss=1.312, acc=60.5% | Val: loss=0.899, acc=69.2% | lr=0.000333
2025-11-24 07:38:37,973 [coscl.py] => Epoch 54/100 | Train: loss=1.314, acc=61.7% | Val: loss=0.895, acc=69.5% | lr=0.000333
2025-11-24 07:38:39,732 [coscl.py] => Epoch 55/100 | Train: loss=1.331, acc=60.8% | Val: loss=0.912, acc=69.2% | lr=0.000333
2025-11-24 07:38:42,118 [coscl.py] => Epoch 56/100 | Train: loss=1.297, acc=61.3% | Val: loss=0.884, acc=70.1% | lr=0.000111
2025-11-24 07:38:43,879 [coscl.py] => Epoch 57/100 | Train: loss=1.288, acc=61.8% | Val: loss=0.889, acc=70.1% | lr=0.000111
2025-11-24 07:38:45,604 [coscl.py] => Epoch 58/100 | Train: loss=1.293, acc=61.7% | Val: loss=0.889, acc=69.7% | lr=0.000111
2025-11-24 07:38:47,592 [coscl.py] => Epoch 59/100 | Train: loss=1.273, acc=62.0% | Val: loss=0.885, acc=70.2% | lr=0.000111
2025-11-24 07:38:49,313 [coscl.py] => Epoch 60/100 | Train: loss=1.292, acc=61.1% | Val: loss=0.889, acc=69.9% | lr=0.000111
2025-11-24 07:38:51,077 [coscl.py] => Epoch 61/100 | Train: loss=1.288, acc=61.2% | Val: loss=0.887, acc=69.8% | lr=0.000111
2025-11-24 07:38:52,865 [coscl.py] => Epoch 62/100 | Train: loss=1.274, acc=62.1% | Val: loss=0.888, acc=69.8% | lr=0.000037
2025-11-24 07:38:54,563 [coscl.py] => Epoch 63/100 | Train: loss=1.293, acc=61.0% | Val: loss=0.885, acc=70.0% | lr=0.000037
2025-11-24 07:38:56,269 [coscl.py] => Epoch 64/100 | Train: loss=1.287, acc=61.1% | Val: loss=0.886, acc=69.8% | lr=0.000037
2025-11-24 07:38:58,248 [coscl.py] => Epoch 65/100 | Train: loss=1.284, acc=61.5% | Val: loss=0.886, acc=69.9% | lr=0.000037
2025-11-24 07:38:59,945 [coscl.py] => Epoch 66/100 | Train: loss=1.291, acc=61.0% | Val: loss=0.888, acc=69.8% | lr=0.000037
2025-11-24 07:39:01,733 [coscl.py] => Epoch 67/100 | Train: loss=1.283, acc=61.3% | Val: loss=0.886, acc=70.1% | lr=0.000012
2025-11-24 07:39:03,520 [coscl.py] => Epoch 68/100 | Train: loss=1.256, acc=63.2% | Val: loss=0.885, acc=70.0% | lr=0.000012
2025-11-24 07:39:05,247 [coscl.py] => Epoch 69/100 | Train: loss=1.279, acc=61.7% | Val: loss=0.885, acc=70.1% | lr=0.000012
2025-11-24 07:39:06,958 [coscl.py] => Epoch 70/100 | Train: loss=1.269, acc=62.8% | Val: loss=0.886, acc=70.0% | lr=0.000012
2025-11-24 07:39:08,813 [coscl.py] => Epoch 71/100 | Train: loss=1.268, acc=62.5% | Val: loss=0.886, acc=70.1% | lr=0.000012
2025-11-24 07:39:14,354 [coscl.py] => Epoch 72/100 | Train: loss=1.270, acc=62.3% | Val: loss=0.887, acc=70.0% | lr=0.000004
2025-11-24 07:39:18,033 [coscl.py] => Epoch 73/100 | Train: loss=1.270, acc=62.1% | Val: loss=0.886, acc=70.0% | lr=0.000004
2025-11-24 07:39:19,983 [coscl.py] => Epoch 74/100 | Train: loss=1.272, acc=62.5% | Val: loss=0.885, acc=70.0% | lr=0.000004
2025-11-24 07:39:21,763 [coscl.py] => Epoch 75/100 | Train: loss=1.283, acc=61.5% | Val: loss=0.886, acc=70.1% | lr=0.000004
2025-11-24 07:39:23,497 [coscl.py] => Epoch 76/100 | Train: loss=1.264, acc=62.0% | Val: loss=0.886, acc=70.0% | lr=0.000004
2025-11-24 07:39:25,603 [coscl.py] => Epoch 77/100 | Train: loss=1.269, acc=61.7% | Val: loss=0.886, acc=70.0% | lr=0.000001
2025-11-24 07:39:27,367 [coscl.py] => Epoch 78/100 | Train: loss=1.270, acc=61.0% | Val: loss=0.886, acc=70.0% | lr=0.000001
2025-11-24 07:39:29,080 [coscl.py] => Epoch 79/100 | Train: loss=1.271, acc=61.2% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:30,909 [coscl.py] => Epoch 80/100 | Train: loss=1.274, acc=62.1% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:32,712 [coscl.py] => Epoch 81/100 | Train: loss=1.278, acc=61.1% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:32,712 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:34,527 [coscl.py] => Epoch 82/100 | Train: loss=1.264, acc=62.6% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:34,528 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:36,281 [coscl.py] => Epoch 83/100 | Train: loss=1.281, acc=62.1% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:36,282 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:38,095 [coscl.py] => Epoch 84/100 | Train: loss=1.259, acc=62.0% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:38,095 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:39,940 [coscl.py] => Epoch 85/100 | Train: loss=1.270, acc=62.0% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:39,940 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:41,671 [coscl.py] => Epoch 86/100 | Train: loss=1.265, acc=62.0% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:41,672 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:43,471 [coscl.py] => Epoch 87/100 | Train: loss=1.266, acc=62.1% | Val: loss=0.885, acc=70.1% | lr=0.000001
2025-11-24 07:39:43,472 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:45,225 [coscl.py] => Epoch 88/100 | Train: loss=1.270, acc=62.0% | Val: loss=0.885, acc=70.1% | lr=0.000001
2025-11-24 07:39:45,226 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:46,940 [coscl.py] => Epoch 89/100 | Train: loss=1.256, acc=61.8% | Val: loss=0.885, acc=70.0% | lr=0.000001
2025-11-24 07:39:46,941 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:48,853 [coscl.py] => Epoch 90/100 | Train: loss=1.275, acc=61.7% | Val: loss=0.885, acc=70.0% | lr=0.000001
2025-11-24 07:39:48,854 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:50,557 [coscl.py] => Epoch 91/100 | Train: loss=1.275, acc=61.4% | Val: loss=0.885, acc=70.0% | lr=0.000001
2025-11-24 07:39:50,557 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:52,316 [coscl.py] => Epoch 92/100 | Train: loss=1.266, acc=61.7% | Val: loss=0.885, acc=70.0% | lr=0.000001
2025-11-24 07:39:52,316 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:54,378 [coscl.py] => Epoch 93/100 | Train: loss=1.264, acc=62.1% | Val: loss=0.885, acc=70.1% | lr=0.000001
2025-11-24 07:39:54,378 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:56,067 [coscl.py] => Epoch 94/100 | Train: loss=1.271, acc=62.0% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:56,067 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:57,933 [coscl.py] => Epoch 95/100 | Train: loss=1.259, acc=62.3% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:39:57,933 [coscl.py] => Learning rate reached minimum
2025-11-24 07:39:59,766 [coscl.py] => Epoch 96/100 | Train: loss=1.275, acc=62.5% | Val: loss=0.886, acc=70.0% | lr=0.000001
2025-11-24 07:39:59,767 [coscl.py] => Learning rate reached minimum
2025-11-24 07:40:01,497 [coscl.py] => Epoch 97/100 | Train: loss=1.260, acc=63.1% | Val: loss=0.885, acc=70.1% | lr=0.000001
2025-11-24 07:40:01,497 [coscl.py] => Learning rate reached minimum
2025-11-24 07:40:03,267 [coscl.py] => Epoch 98/100 | Train: loss=1.279, acc=61.3% | Val: loss=0.885, acc=70.0% | lr=0.000001
2025-11-24 07:40:03,268 [coscl.py] => Learning rate reached minimum
2025-11-24 07:40:05,178 [coscl.py] => Epoch 99/100 | Train: loss=1.272, acc=61.6% | Val: loss=0.886, acc=70.1% | lr=0.000001
2025-11-24 07:40:05,178 [coscl.py] => Learning rate reached minimum
2025-11-24 07:40:06,973 [coscl.py] => Epoch 100/100 | Train: loss=1.269, acc=62.2% | Val: loss=0.885, acc=70.1% | lr=0.000001
2025-11-24 07:40:06,973 [coscl.py] => Learning rate reached minimum
2025-11-24 07:40:10,075 [trainer.py] => No NME accuracy.
2025-11-24 07:40:10,076 [trainer.py] => CNN: {'total': np.float64(25.6), '00-09': np.float64(53.9), '10-19': np.float64(35.6), '20-29': np.float64(42.2), '30-39': np.float64(11.7), '40-49': np.float64(20.4), '50-59': np.float64(19.1), '60-69': np.float64(19.8), '70-79': np.float64(9.5), '80-89': np.float64(18.2), 'old': np.float64(26.52), 'new': np.float64(18.2)}
2025-11-24 07:40:10,076 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95), np.float64(38.3), np.float64(34.78), np.float64(31.46), np.float64(28.06), np.float64(25.6)]
2025-11-24 07:40:10,076 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92), np.float64(75.02), np.float64(71.68), np.float64(68.34), np.float64(63.76), np.float64(60.99)]

2025-11-24 07:40:10,076 [trainer.py] => Average Accuracy (CNN): 42.61333333333333 

2025-11-24 07:40:10,077 [trainer.py] => All params: 773260
2025-11-24 07:40:10,077 [trainer.py] => Trainable params: 773260
2025-11-24 07:40:12,098 [coscl.py] => Epoch 1/100 | Train: loss=2.013, acc=39.7% | Val: loss=1.098, acc=63.9% | lr=0.001000
2025-11-24 07:40:13,837 [coscl.py] => Epoch 2/100 | Train: loss=1.637, acc=56.1% | Val: loss=0.993, acc=67.6% | lr=0.001000
2025-11-24 07:40:15,587 [coscl.py] => Epoch 3/100 | Train: loss=1.521, acc=58.0% | Val: loss=0.940, acc=69.3% | lr=0.001000
2025-11-24 07:40:17,338 [coscl.py] => Epoch 4/100 | Train: loss=1.448, acc=59.8% | Val: loss=0.910, acc=69.8% | lr=0.001000
2025-11-24 07:40:19,032 [coscl.py] => Epoch 5/100 | Train: loss=1.395, acc=61.0% | Val: loss=0.894, acc=70.5% | lr=0.001000
2025-11-24 07:40:20,897 [coscl.py] => Epoch 6/100 | Train: loss=1.369, acc=61.8% | Val: loss=0.878, acc=70.1% | lr=0.001000
2025-11-24 07:40:22,703 [coscl.py] => Epoch 7/100 | Train: loss=1.348, acc=62.3% | Val: loss=0.844, acc=71.5% | lr=0.001000
2025-11-24 07:40:24,446 [coscl.py] => Epoch 8/100 | Train: loss=1.341, acc=62.8% | Val: loss=0.858, acc=71.0% | lr=0.001000
2025-11-24 07:40:26,243 [coscl.py] => Epoch 9/100 | Train: loss=1.321, acc=62.8% | Val: loss=0.833, acc=72.3% | lr=0.001000
2025-11-24 07:40:28,331 [coscl.py] => Epoch 10/100 | Train: loss=1.295, acc=64.6% | Val: loss=0.857, acc=71.0% | lr=0.001000
2025-11-24 07:40:30,248 [coscl.py] => Epoch 11/100 | Train: loss=1.298, acc=63.4% | Val: loss=0.866, acc=70.6% | lr=0.001000
2025-11-24 07:40:32,136 [coscl.py] => Epoch 12/100 | Train: loss=1.300, acc=64.4% | Val: loss=0.865, acc=70.2% | lr=0.001000
2025-11-24 07:40:34,032 [coscl.py] => Epoch 13/100 | Train: loss=1.295, acc=63.3% | Val: loss=0.835, acc=71.4% | lr=0.001000
2025-11-24 07:40:35,803 [coscl.py] => Epoch 14/100 | Train: loss=1.268, acc=64.5% | Val: loss=0.810, acc=72.7% | lr=0.001000
2025-11-24 07:40:37,674 [coscl.py] => Epoch 15/100 | Train: loss=1.282, acc=63.3% | Val: loss=0.850, acc=70.7% | lr=0.001000
2025-11-24 07:40:39,564 [coscl.py] => Epoch 16/100 | Train: loss=1.266, acc=64.6% | Val: loss=0.812, acc=72.5% | lr=0.001000
2025-11-24 07:40:41,321 [coscl.py] => Epoch 17/100 | Train: loss=1.278, acc=64.3% | Val: loss=0.801, acc=72.9% | lr=0.001000
2025-11-24 07:40:43,069 [coscl.py] => Epoch 18/100 | Train: loss=1.256, acc=65.4% | Val: loss=0.817, acc=71.5% | lr=0.001000
2025-11-24 07:40:44,856 [coscl.py] => Epoch 19/100 | Train: loss=1.259, acc=65.3% | Val: loss=0.790, acc=73.2% | lr=0.001000
2025-11-24 07:40:46,655 [coscl.py] => Epoch 20/100 | Train: loss=1.258, acc=64.8% | Val: loss=0.810, acc=72.4% | lr=0.001000
2025-11-24 07:40:48,345 [coscl.py] => Epoch 21/100 | Train: loss=1.254, acc=65.5% | Val: loss=0.830, acc=71.8% | lr=0.001000
2025-11-24 07:40:50,245 [coscl.py] => Epoch 22/100 | Train: loss=1.269, acc=64.3% | Val: loss=0.781, acc=74.0% | lr=0.001000
2025-11-24 07:40:51,994 [coscl.py] => Epoch 23/100 | Train: loss=1.264, acc=64.7% | Val: loss=0.780, acc=73.8% | lr=0.001000
2025-11-24 07:40:53,863 [coscl.py] => Epoch 24/100 | Train: loss=1.249, acc=65.5% | Val: loss=0.787, acc=73.1% | lr=0.001000
2025-11-24 07:40:55,693 [coscl.py] => Epoch 25/100 | Train: loss=1.255, acc=65.4% | Val: loss=0.808, acc=72.3% | lr=0.001000
2025-11-24 07:40:57,458 [coscl.py] => Epoch 26/100 | Train: loss=1.256, acc=65.2% | Val: loss=0.795, acc=72.9% | lr=0.001000
2025-11-24 07:40:59,177 [coscl.py] => Epoch 27/100 | Train: loss=1.245, acc=66.1% | Val: loss=0.808, acc=72.1% | lr=0.001000
2025-11-24 07:41:01,043 [coscl.py] => Epoch 28/100 | Train: loss=1.260, acc=65.1% | Val: loss=0.790, acc=73.4% | lr=0.001000
2025-11-24 07:41:02,735 [coscl.py] => Epoch 29/100 | Train: loss=1.213, acc=65.7% | Val: loss=0.766, acc=74.1% | lr=0.000333
2025-11-24 07:41:04,503 [coscl.py] => Epoch 30/100 | Train: loss=1.188, acc=65.7% | Val: loss=0.776, acc=73.5% | lr=0.000333
2025-11-24 07:41:06,672 [coscl.py] => Epoch 31/100 | Train: loss=1.182, acc=66.0% | Val: loss=0.773, acc=73.8% | lr=0.000333
2025-11-24 07:41:08,425 [coscl.py] => Epoch 32/100 | Train: loss=1.160, acc=66.4% | Val: loss=0.775, acc=73.1% | lr=0.000333
2025-11-24 07:41:10,306 [coscl.py] => Epoch 33/100 | Train: loss=1.174, acc=66.0% | Val: loss=0.773, acc=73.6% | lr=0.000333
2025-11-24 07:41:12,048 [coscl.py] => Epoch 34/100 | Train: loss=1.165, acc=66.9% | Val: loss=0.760, acc=74.1% | lr=0.000333
2025-11-24 07:41:13,824 [coscl.py] => Epoch 35/100 | Train: loss=1.181, acc=65.8% | Val: loss=0.767, acc=74.0% | lr=0.000333
2025-11-24 07:41:15,659 [coscl.py] => Epoch 36/100 | Train: loss=1.155, acc=66.8% | Val: loss=0.760, acc=74.2% | lr=0.000333
2025-11-24 07:41:17,388 [coscl.py] => Epoch 37/100 | Train: loss=1.163, acc=66.6% | Val: loss=0.772, acc=73.7% | lr=0.000333
2025-11-24 07:41:19,310 [coscl.py] => Epoch 38/100 | Train: loss=1.163, acc=66.1% | Val: loss=0.773, acc=73.7% | lr=0.000333
2025-11-24 07:41:21,075 [coscl.py] => Epoch 39/100 | Train: loss=1.167, acc=65.4% | Val: loss=0.765, acc=73.8% | lr=0.000333
2025-11-24 07:41:22,859 [coscl.py] => Epoch 40/100 | Train: loss=1.162, acc=66.3% | Val: loss=0.761, acc=74.2% | lr=0.000333
2025-11-24 07:41:24,703 [coscl.py] => Epoch 41/100 | Train: loss=1.176, acc=65.5% | Val: loss=0.760, acc=74.0% | lr=0.000333
2025-11-24 07:41:26,496 [coscl.py] => Epoch 42/100 | Train: loss=1.171, acc=65.6% | Val: loss=0.774, acc=73.3% | lr=0.000333
2025-11-24 07:41:28,536 [coscl.py] => Epoch 43/100 | Train: loss=1.160, acc=66.8% | Val: loss=0.769, acc=73.7% | lr=0.000333
2025-11-24 07:41:30,274 [coscl.py] => Epoch 44/100 | Train: loss=1.160, acc=66.2% | Val: loss=0.778, acc=73.7% | lr=0.000333
2025-11-24 07:41:32,165 [coscl.py] => Epoch 45/100 | Train: loss=1.147, acc=67.8% | Val: loss=0.753, acc=74.4% | lr=0.000333
2025-11-24 07:41:34,058 [coscl.py] => Epoch 46/100 | Train: loss=1.167, acc=67.0% | Val: loss=0.765, acc=73.9% | lr=0.000333
2025-11-24 07:41:35,771 [coscl.py] => Epoch 47/100 | Train: loss=1.151, acc=66.8% | Val: loss=0.771, acc=73.8% | lr=0.000333
2025-11-24 07:41:37,925 [coscl.py] => Epoch 48/100 | Train: loss=1.171, acc=66.3% | Val: loss=0.784, acc=73.2% | lr=0.000333
2025-11-24 07:41:39,746 [coscl.py] => Epoch 49/100 | Train: loss=1.153, acc=66.8% | Val: loss=0.761, acc=73.5% | lr=0.000333
2025-11-24 07:41:42,029 [coscl.py] => Epoch 50/100 | Train: loss=1.157, acc=66.6% | Val: loss=0.774, acc=73.2% | lr=0.000333
2025-11-24 07:41:43,848 [coscl.py] => Epoch 51/100 | Train: loss=1.157, acc=66.8% | Val: loss=0.754, acc=74.4% | lr=0.000111
2025-11-24 07:41:45,538 [coscl.py] => Epoch 52/100 | Train: loss=1.134, acc=66.8% | Val: loss=0.755, acc=74.4% | lr=0.000111
2025-11-24 07:41:47,609 [coscl.py] => Epoch 53/100 | Train: loss=1.146, acc=66.9% | Val: loss=0.755, acc=74.2% | lr=0.000111
2025-11-24 07:41:49,456 [coscl.py] => Epoch 54/100 | Train: loss=1.142, acc=66.3% | Val: loss=0.752, acc=74.4% | lr=0.000111
2025-11-24 07:41:51,151 [coscl.py] => Epoch 55/100 | Train: loss=1.137, acc=67.1% | Val: loss=0.760, acc=74.3% | lr=0.000111
2025-11-24 07:41:52,823 [coscl.py] => Epoch 56/100 | Train: loss=1.139, acc=66.6% | Val: loss=0.756, acc=74.2% | lr=0.000111
2025-11-24 07:41:54,512 [coscl.py] => Epoch 57/100 | Train: loss=1.131, acc=66.8% | Val: loss=0.760, acc=74.2% | lr=0.000111
2025-11-24 07:41:56,370 [coscl.py] => Epoch 58/100 | Train: loss=1.140, acc=67.3% | Val: loss=0.753, acc=74.4% | lr=0.000111
2025-11-24 07:41:58,277 [coscl.py] => Epoch 59/100 | Train: loss=1.128, acc=67.0% | Val: loss=0.756, acc=74.2% | lr=0.000111
2025-11-24 07:41:59,994 [coscl.py] => Epoch 60/100 | Train: loss=1.131, acc=67.0% | Val: loss=0.753, acc=74.3% | lr=0.000037
2025-11-24 07:42:01,795 [coscl.py] => Epoch 61/100 | Train: loss=1.126, acc=67.7% | Val: loss=0.756, acc=74.2% | lr=0.000037
2025-11-24 07:42:03,584 [coscl.py] => Epoch 62/100 | Train: loss=1.116, acc=67.6% | Val: loss=0.758, acc=74.2% | lr=0.000037
2025-11-24 07:42:05,461 [coscl.py] => Epoch 63/100 | Train: loss=1.118, acc=67.8% | Val: loss=0.754, acc=74.3% | lr=0.000037
2025-11-24 07:42:07,209 [coscl.py] => Epoch 64/100 | Train: loss=1.124, acc=67.0% | Val: loss=0.750, acc=74.6% | lr=0.000037
2025-11-24 07:42:08,914 [coscl.py] => Epoch 65/100 | Train: loss=1.113, acc=67.9% | Val: loss=0.754, acc=74.4% | lr=0.000037
2025-11-24 07:42:13,001 [coscl.py] => Epoch 66/100 | Train: loss=1.117, acc=67.8% | Val: loss=0.752, acc=74.3% | lr=0.000037
2025-11-24 07:42:15,189 [coscl.py] => Epoch 67/100 | Train: loss=1.124, acc=66.9% | Val: loss=0.759, acc=74.2% | lr=0.000037
2025-11-24 07:42:17,304 [coscl.py] => Epoch 68/100 | Train: loss=1.120, acc=67.3% | Val: loss=0.757, acc=74.2% | lr=0.000037
2025-11-24 07:42:19,053 [coscl.py] => Epoch 69/100 | Train: loss=1.107, acc=67.3% | Val: loss=0.750, acc=74.5% | lr=0.000037
2025-11-24 07:42:20,970 [coscl.py] => Epoch 70/100 | Train: loss=1.125, acc=66.7% | Val: loss=0.753, acc=74.2% | lr=0.000012
2025-11-24 07:42:22,867 [coscl.py] => Epoch 71/100 | Train: loss=1.107, acc=67.3% | Val: loss=0.752, acc=74.2% | lr=0.000012
2025-11-24 07:42:24,715 [coscl.py] => Epoch 72/100 | Train: loss=1.118, acc=68.3% | Val: loss=0.753, acc=74.3% | lr=0.000012
2025-11-24 07:42:26,462 [coscl.py] => Epoch 73/100 | Train: loss=1.117, acc=68.3% | Val: loss=0.753, acc=74.5% | lr=0.000012
2025-11-24 07:42:28,260 [coscl.py] => Epoch 74/100 | Train: loss=1.126, acc=67.0% | Val: loss=0.755, acc=74.3% | lr=0.000012
2025-11-24 07:42:30,026 [coscl.py] => Epoch 75/100 | Train: loss=1.109, acc=67.3% | Val: loss=0.754, acc=74.5% | lr=0.000004
2025-11-24 07:42:31,723 [coscl.py] => Epoch 76/100 | Train: loss=1.118, acc=67.2% | Val: loss=0.754, acc=74.5% | lr=0.000004
2025-11-24 07:42:33,543 [coscl.py] => Epoch 77/100 | Train: loss=1.118, acc=67.0% | Val: loss=0.754, acc=74.4% | lr=0.000004
2025-11-24 07:42:35,372 [coscl.py] => Epoch 78/100 | Train: loss=1.122, acc=67.0% | Val: loss=0.754, acc=74.4% | lr=0.000004
2025-11-24 07:42:37,059 [coscl.py] => Epoch 79/100 | Train: loss=1.112, acc=67.2% | Val: loss=0.755, acc=74.4% | lr=0.000004
2025-11-24 07:42:38,954 [coscl.py] => Epoch 80/100 | Train: loss=1.123, acc=66.7% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:40,815 [coscl.py] => Epoch 81/100 | Train: loss=1.114, acc=67.7% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:42,620 [coscl.py] => Epoch 82/100 | Train: loss=1.121, acc=66.7% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:44,352 [coscl.py] => Epoch 83/100 | Train: loss=1.114, acc=67.6% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:46,103 [coscl.py] => Epoch 84/100 | Train: loss=1.115, acc=67.0% | Val: loss=0.754, acc=74.5% | lr=0.000001
2025-11-24 07:42:46,103 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:47,901 [coscl.py] => Epoch 85/100 | Train: loss=1.121, acc=66.9% | Val: loss=0.754, acc=74.5% | lr=0.000001
2025-11-24 07:42:47,901 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:49,714 [coscl.py] => Epoch 86/100 | Train: loss=1.114, acc=67.2% | Val: loss=0.753, acc=74.5% | lr=0.000001
2025-11-24 07:42:49,715 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:51,970 [coscl.py] => Epoch 87/100 | Train: loss=1.114, acc=67.1% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:51,970 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:53,809 [coscl.py] => Epoch 88/100 | Train: loss=1.118, acc=66.9% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:53,810 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:55,546 [coscl.py] => Epoch 89/100 | Train: loss=1.122, acc=66.7% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:55,547 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:57,442 [coscl.py] => Epoch 90/100 | Train: loss=1.122, acc=67.2% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:57,443 [coscl.py] => Learning rate reached minimum
2025-11-24 07:42:59,291 [coscl.py] => Epoch 91/100 | Train: loss=1.123, acc=67.1% | Val: loss=0.754, acc=74.4% | lr=0.000001
2025-11-24 07:42:59,292 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:01,068 [coscl.py] => Epoch 92/100 | Train: loss=1.121, acc=67.2% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:01,068 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:02,861 [coscl.py] => Epoch 93/100 | Train: loss=1.117, acc=67.4% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:02,861 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:04,655 [coscl.py] => Epoch 94/100 | Train: loss=1.121, acc=67.4% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:04,656 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:06,652 [coscl.py] => Epoch 95/100 | Train: loss=1.120, acc=67.2% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:06,652 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:08,497 [coscl.py] => Epoch 96/100 | Train: loss=1.118, acc=66.6% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:08,498 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:10,303 [coscl.py] => Epoch 97/100 | Train: loss=1.116, acc=67.0% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:10,303 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:12,632 [coscl.py] => Epoch 98/100 | Train: loss=1.116, acc=67.1% | Val: loss=0.753, acc=74.5% | lr=0.000001
2025-11-24 07:43:12,633 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:14,390 [coscl.py] => Epoch 99/100 | Train: loss=1.116, acc=67.0% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:14,391 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:16,145 [coscl.py] => Epoch 100/100 | Train: loss=1.105, acc=67.7% | Val: loss=0.753, acc=74.4% | lr=0.000001
2025-11-24 07:43:16,145 [coscl.py] => Learning rate reached minimum
2025-11-24 07:43:19,613 [trainer.py] => No NME accuracy.
2025-11-24 07:43:19,615 [trainer.py] => CNN: {'total': np.float64(24.07), '00-09': np.float64(52.3), '10-19': np.float64(35.6), '20-29': np.float64(40.8), '30-39': np.float64(9.7), '40-49': np.float64(19.3), '50-59': np.float64(17.9), '60-69': np.float64(18.7), '70-79': np.float64(8.4), '80-89': np.float64(16.1), '90-99': np.float64(21.9), 'old': np.float64(24.31), 'new': np.float64(21.9)}
2025-11-24 07:43:19,615 [trainer.py] => CNN top1 curve: [np.float64(72.7), np.float64(58.0), np.float64(51.67), np.float64(42.95), np.float64(38.3), np.float64(34.78), np.float64(31.46), np.float64(28.06), np.float64(25.6), np.float64(24.07)]
2025-11-24 07:43:19,615 [trainer.py] => CNN top5 curve: [np.float64(98.0), np.float64(91.1), np.float64(87.4), np.float64(79.92), np.float64(75.02), np.float64(71.68), np.float64(68.34), np.float64(63.76), np.float64(60.99), np.float64(58.79)]

2025-11-24 07:43:19,615 [trainer.py] => Average Accuracy (CNN): 40.759 

